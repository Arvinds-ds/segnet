{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Semantic Segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imread\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from utils import unpool_with_argmax\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file = 'CamVid/train.txt'\n",
    "val_file = 'CamVid/val.txt'\n",
    "test_file = 'CamVid/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT = 72\n",
    "IMAGE_WIDTH = 96\n",
    "IMAGE_DEPTH = 3\n",
    "NUM_CLASSES = 12\n",
    "TRAIN_BATCH_SIZE=32\n",
    "VAL_BATCH_SIZE=TRAIN_BATCH_SIZE\n",
    "TEST_BATCH_SIZE = 1\n",
    "NUM_ITERS = 2000\n",
    "NUM_TRAIN = 367"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_label_colors():\n",
    "    Sky = [128,128,128]\n",
    "    Building = [128,0,0]\n",
    "    Pole = [192,192,128]\n",
    "    Road_marking = [255,69,0]\n",
    "    Road = [128,64,128]\n",
    "    Pavement = [60,40,222]\n",
    "    Tree = [128,128,0]\n",
    "    SignSymbol = [192,128,128]\n",
    "    Fence = [64,64,128]\n",
    "    Car = [64,0,128]\n",
    "    Pedestrian = [64,64,0]\n",
    "    Bicyclist = [0,128,192]\n",
    "    Unlabelled = [0,0,0]\n",
    "\n",
    "    label_colors = np.array([Sky, Building, Pole, Road, Pavement, Tree, SignSymbol, \n",
    "                             Fence, Car, Pedestrian, Bicyclist, Unlabelled])\n",
    "    return label_colors\n",
    "\n",
    "def img_annot_to_rgb(img_annot):\n",
    "    r = img_annot.copy()\n",
    "    g = img_annot.copy()\n",
    "    b = img_annot.copy()\n",
    "    label_colors = get_label_colors()\n",
    "    for i in range(len(label_colors)):\n",
    "        r[img_annot==i]=label_colors[i,0]\n",
    "        g[img_annot==i]=label_colors[i,1]\n",
    "        b[img_annot==i]=label_colors[i,2]\n",
    "    return np.stack([r,g,b],axis=2)/255.0\n",
    "\n",
    "def visualize_image_annot(img_data, annot_data, predicted_annot=None):\n",
    "    if predicted_annot is None:\n",
    "        fig, ax = plt.subplots(1,2,figsize=(10,12))\n",
    "        ax[0].imshow(img_data)\n",
    "        ax[0].set_title('Original Image')\n",
    "        ax[1].imshow(img_annot_to_rgb(annot_data))\n",
    "        ax[1].set_title('True Segmentation')\n",
    "        plt.show()\n",
    "    else:\n",
    "        fig, ax = plt.subplots(1,3,figsize=(10,12))\n",
    "        ax[0].imshow(img_data)\n",
    "        ax[0].set_title('Original Image')\n",
    "        ax[1].imshow(img_annot_to_rgb(predicted_annot))\n",
    "        ax[1].set_title('Predicted Segmentation')\n",
    "        ax[2].imshow(img_annot_to_rgb(annot_data))\n",
    "        ax[2].set_title('True Segmentation')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(file, train=True, batch_size=10, labels=True):\n",
    "    def _load_image(filename):\n",
    "        image_string = tf.read_file(filenames[0])\n",
    "        image_decoded = tf.image.decode_png(image_string, channels=3)\n",
    "        image_decoded = tf.image.convert_image_dtype(image_decoded,tf.float32)\n",
    "        return image_decoded\n",
    "\n",
    "    def _load_image_with_labels(filenames):\n",
    "        image_string = tf.read_file(filenames[0])\n",
    "        image_decoded = tf.image.decode_png(image_string, channels=3)\n",
    "        image_decoded = tf.image.convert_image_dtype(image_decoded,tf.float32)\n",
    "        image_decoded = tf.image.resize_images(image_decoded, [IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "        annot_string = tf.read_file(filenames[1])\n",
    "        annot_decoded = tf.image.decode_png(annot_string, channels=1)\n",
    "        annot_decoded = tf.image.resize_images(annot_decoded, [IMAGE_HEIGHT,IMAGE_WIDTH])\n",
    "        annot_decoded = tf.squeeze(annot_decoded,axis=2)\n",
    "        annot_decoded = tf.cast(annot_decoded, tf.int64)\n",
    "        return image_decoded, annot_decoded\n",
    "\n",
    "    dataset = tf.contrib.data.Dataset.from_tensor_slices(tf.constant([file]))\n",
    "    dataset =  dataset.flat_map(lambda filename: tf.contrib.data.TextLineDataset(filename))\n",
    "    dataset = dataset.map(lambda line: tf.string_split([line], delimiter=' ').values)\n",
    "    if labels:\n",
    "        dataset = dataset.map(_load_image_with_labels)\n",
    "    else:\n",
    "        dataset = dataset.map(_load_image)\n",
    "    if train is True:\n",
    "        dataset = dataset.shuffle(buffer_size=batch_size*3)\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    return iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference_scope(is_training, batch_norm_decay=0.9):\n",
    "    with slim.arg_scope([slim.conv2d],\n",
    "                        activation_fn=tf.nn.relu,\n",
    "                        weights_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "                        normalizer_fn=slim.batch_norm,\n",
    "                        stride=1,\n",
    "                        padding='SAME'):\n",
    "\n",
    "        with slim.arg_scope([slim.batch_norm],\n",
    "                            is_training=is_training,\n",
    "                            decay=batch_norm_decay) as scope:\n",
    "            return scope\n",
    "\n",
    "def inference(images, class_inc_bg = None):\n",
    "\n",
    "    tf.summary.image('input', images, max_outputs=3)\n",
    "\n",
    "    with tf.variable_scope('pool1'):\n",
    "        net = slim.conv2d(images, 64, [3, 3], scope='conv1_1')\n",
    "        net = slim.conv2d(net, 64, [3, 3], scope='conv1_2')\n",
    "        net, arg1 = tf.nn.max_pool_with_argmax(net, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='maxpool1')\n",
    "\n",
    "    with tf.variable_scope('pool2'):\n",
    "        net = slim.conv2d(net, 128, [3, 3], scope='conv2_1')\n",
    "        net = slim.conv2d(net, 128, [3, 3], scope='conv2_2')\n",
    "        net, arg2 = tf.nn.max_pool_with_argmax(net, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='maxpool2')\n",
    "\n",
    "    with tf.variable_scope('pool3'):\n",
    "        net = slim.conv2d(net, 256, [3, 3], scope='conv3_1')\n",
    "        net = slim.conv2d(net, 256, [3, 3], scope='conv3_2')\n",
    "        net = slim.conv2d(net, 256, [3, 3], scope='conv3_3')\n",
    "        net, arg3 = tf.nn.max_pool_with_argmax(net, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='maxpool3')\n",
    "\n",
    "    with tf.variable_scope('unpool3'):\n",
    "        net = unpool_with_argmax(net, arg3, name='maxunpool3')\n",
    "        net = slim.conv2d(net, 256, [3, 3], scope='uconv3_3')\n",
    "        net = slim.conv2d(net, 256, [3, 3], scope='uconv3_2')\n",
    "        net = slim.conv2d(net, 128, [3, 3], scope='uconv3_1')\n",
    "\n",
    "    with tf.variable_scope('unpool2'):\n",
    "        net = unpool_with_argmax(net, arg2, name='maxunpool2')\n",
    "        net = slim.conv2d(net, 128, [3, 3], scope='uconv2_2')\n",
    "        net = slim.conv2d(net, 64, [3, 3], scope='uconv2_1')\n",
    "\n",
    "    with tf.variable_scope('unpool1'):\n",
    "        net = unpool_with_argmax(net, arg1, name='maxunpool1')\n",
    "        net = slim.conv2d(net, 64, [3, 3], scope='uconv1_2')\n",
    "        logits = slim.conv2d(net, class_inc_bg, [3, 3], scope='uconv1_1')\n",
    "    predicted_annotations = tf.argmax(logits,axis=3)\n",
    "    return logits, predicted_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "train_iterator = load_data(train_file, batch_size=TRAIN_BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_iterator = load_data(val_file, train=False, batch_size=TRAIN_BATCH_SIZE)\n",
    "test_iterator = load_data(test_file, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(train_iterator.initializer)\n",
    "X,y = sess.run(train_iterator.get_next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAADtCAYAAACbHvDEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsvXecXVd1L/5dt0+vKjNqo25L7sa2bGOQAVOM6QTCg8R5\nQODxkjxeQkJJXsLlpZMfJeWXBAMBEhJKCGBjwLjKBVfJlmTJ6mXURjOaXm6/d78/9j57rZm5oxlp\nRjOSvL6fD8z2Oufsvc8+5x6ds75rfRcZY6BQKBQKhUKhODuE5noCCoVCoVAoFBcy9GVKoVAoFAqF\nYhrQlymFQqFQKBSKaUBfphQKhUKhUCimAX2ZUigUCoVCoZgG9GVKoVAoFAqFYhrQl6mXGYjoD4no\nazO97xT6MkS0aib6UigUCgWDiO4kop/P9TxeztCXqQsYRPQbRPQiEaWI6CQR/RMR1Z/uGGPMXxhj\nPjyV/s9k3+mAiDYR0TkfR6FQzCyIaFj8r0REafHf75+F8ZcS0Y+IqJuIBtzz8NfO9bgzCSL6MBFt\nOoP9VxHRKIFIY8y3jDFvmvHJKaYMfZm6QEFEnwDw1wD+AEAdgA0AlgF4gIhiExwTmb0ZKhSKix3G\nmOrgfwCOAHiLsP372P3PwTPo3wEcBLAUQBOAOwF0zfAYCsWk0JepCxBEVAvgcwB+xxhznzEmb4w5\nDOA9ANoAfMDtlySiHxDRt4loEMBvONu3RV+/TkTtRNRDRH9MRIeJ6HXi+G+7dpuj6u4koiPuS/CP\nRD/XE9FTRNRPRB1E9A8TvdRNcm4biegYEX2SiLpcX28notuJaC8R9RLRH051XCJ6PRHtcV+t/0hE\nj0ovGBF9kIh2EVEfEf2CiJad6ZwVCkV5ENGfEdH3iOg7RDQE4APueZQU+7yOiA6L/17svE2niOgQ\nEf3WaYa4DsA3jDEpY0zBGPO8MeYXoq+biehp93zYSkSvEttWEtETRDRERPc7z/433bZV7nn3G+55\n1EtEv0lENzjvVz8R/e2Yc/0wEe12z5KfE9ESZ4+4vj5KRPvd9r9z2y4H8A8AbnHevG5nf6ub76B7\n3v6xGOoxt0/gAbxurHeLiF5JRJvdc+9ZIrpBbHuCiD5HRE+6c7+PiBonu5aK00Nfpi5M3AQgAeCH\n0miMGQbwMwC3CfPbAPwAQD3sV5wHEa0D8I8A3g+gBdbDtWiSsV8JYC2A1wL4EyK61NmLAH4XQDOA\nG932/3mG5xVgIez5LQLwJwC+CvuCeC2AWwD8MREtn2xcImqGPffPwH617oFdO7jtbwPwhwDeCWAe\ngMcBfOcs56xQKMrjHQD+A/b58r3T7UhEIQD3AngO9vd/G4A/IKLXTnDI0wD+iYjeG7y8iL6WALgH\nwGcBNAL4NIAfElGT2+W7AH4J+2z4M7iP0DF4BYCVbtvfuT5eA+Ay2BfDm91Y74JlCd4G+yx5xp2z\nxO2wz7Cr3bGvM8a8COC3ATzuvHnNbt9h2OdyPYC3APg4Ed3htr0KGOUVfG7MeTcD+CmAL7hz+3sA\nPyOiBrHbf4P14i0AUAXg98qcu+IMoC9TFyaaAXQbYwpltnW47QGeMsb82BhTMsakx+z7bgA/McY8\nYYzJwb64TFas8XPGmLQxZhuAbQCuBABjzBZjzNPu6/AwgK8AePWZnxoAIA/gz40xedgHXjOAvzXG\nDBljdgJ4aYrj3g5gpzHmh26t/g7ASTHO/wDwl8aYXW77XwC4Sr1TCsWM4gljzE8meAaNxY0Aal28\nZs4Ysx/A1wH86gT7vxPAU7AvTO1E9DwRXeu2/TqAe4wxv3Bj3wf7zHojEa0AcAWApBvnMdgXkLH4\nU2NM1hjzMwA5AN82xpwyxhwD8ATsixFgnyV/YYzZ454lfwbgeiKSH6d/aYwZcM+pTQCummgRjDEP\nG2N2unlvg30OTvV5+hbY59533HPx32Cp0DeLfb5ujNlnjEkB+M/TzUUxNejL1IWJbgDNVD7+oMVt\nD3D0NP20yu3uh9UzydjyZSQFoBoAiGgNEd1LNhB+EPbFpLlcB1NAjzGm6NrBw7dTbE9Pcdyx52cA\nHBP9LAPwt85l3w+gFwBhcu+cQqGYOk73DBqLZQCWBr9J97v8JKy3ehyMMb3GmE8aY9bBell2AviR\n6Ot9Y/raAPtcaIV9zsiXu3HzNMaMfe6UfQ65sf5/MU43gBKAxWL/ss/OciCiG8km5pwiogEAH8bU\nn6etANrH2Nox+rk25bkopgZ9mbow8RSALOxXmQcRVQN4E4CHhPl0nqYOiB87EVXAuoXPBv8EYDeA\n1caYWlj6jM6yr5kad+z5EUY/3I4C+Kgxpl78r8IY8+QszFuheLlg7DNoBECl+G/5onQUwL4xv8ka\nY8xbJh3EmFOw1NYSIqpzfX1jTF9Vxpi/gX02NBFRQnSxpEy3U8VRAB8q8yx5ZgrHlntGfxfAfwFY\nYoypA/A18HNtMvbgBOzLncRSAMenMBfFWUJfpi5AGGMGYAPQ/56I3khEUSJqA/B9WM/Lv02xqx8A\neAsR3UQ2aDuJs38BqgEwCGCYiC4B8LGz7Gcmx/0pgMvJBrBHAPwWRj+4/xnAZ4hoPQAQUR0R/cos\nzVuheLliK4A3E1EDEbUA+F9i21MAckT0CSJKEFGYiC4X1N0oENHniWi9268W9ve/2z0j/w3AO4jo\nNrc9QUS3ElGrMeYAgBcBfJaIYkT0Soymwc4U/wzgj4IYUiKqJ6J3T/HYTgCLiSgqbDUAeo0xGSLa\ngNE0ZxcA46jKcrgXwHoXRxYhov8GYBXK05iKGYK+TF2gMMZ8HtYL8//Bvkw8A/t19FpjTHaKfewE\n8DuwX0EdsEGPXbBerzPF78MGNQ7BBoyfNtB0BjHhuMaYbgC/AuDzsPTlOgCb4c7PGPMjWHmJ7zqK\ncAesZ0+hUJw7fBPALljq6T7Y5w8AwMUb3Q7gegCHYemyrwConaCvagB3AxgAcACW4nq76+swbPD7\nHwM4BSvd8Anwv3vvgw3m7oGNufoezu7ZB2PMfwL4IoD/dM+S7QDeMMXDHwCwD0AnEQX028cA/CXZ\nDMg/hP1QDsYaAvCXAJ5xtOIrxszlFIC3AviUO7ffBXCHMabvbM5NMTWQDSNRKDxN2A9LmR2a6/nM\nNFym0DEA7zfGPDLX81EoFOcPiOi/AGw1xvzpXM9FceFBPVMvcxDRW4iokoiqYL1cL8J+EV4UIKI3\nOJd7HBxP9fQcT0uhUMwxyGrULSeiEBHdDuAOAD+e63kpLkzoy5TibbABiycArAbwq+biclfeCOv+\n74ZNGX77FNKzFQrFxY9WWAHMIQBfAvCbTvdJoThjKM2nUCgUCoVCMQ1MyzPlMsn2kJXI//RMTUqh\nUChmA/oMUygUM4Gz9kwRURjAXli5/2Ow8v/vM8a8NHPTUygUinMDfYYpFIqZwnQqeF8PYL8x5iAA\nENF3YeNvJnwQRaIRE4/F7X+EnJyReJmrb+Bai5mcFcAOhcPeFo2yBNLgwKDtM8K1dKuqKtwx7HA7\neZQFr5estLIcqeERb6uu5YzbQi5nx4mx3EeIuK9iqQQAING/KZZ8+4Qbq6a+jufs5l8s8nn29LDI\n+IKFrQCA4ZEhMSafZyxhz2locNDbWlpafLtk3JzAKJV4TsHLclHYJMqJSpky20Kh8XsSTSRJReO2\nl9vXCO05uT24JeSL/uijjbOV6Z/4mLC4dyhkr1k0Imzi+GDNS3JOk0huya3l1iywGcNrHxb3U7C9\nBHltxDm5tlynorjfSmW+g0qjjO54YQoJX3Q0Gh4353KqgHJ8E/QvDpL3azB+WAy0bcuWbmPMvPGz\nnXOc0TOsspJMff0szu4iQkcHt+XzS6E439HR0TGl59d0XqYWYbT8/jEAN4zdiYg+AuAjABCLxbD+\nskusPWaFZwuFnN/3be9hXbK97fblorKWX0xaFvN0H7zHinw3NLFC/oabrgQAVFTFve3zn/h93/7z\nu+4CAGz+5bPe9urX3+rbp45ZgdiFSxZ4WyLKQr0DmYy1VVV5W25w2Lf/5BOWJXjdHSxVNL/BPn2H\nhvg8v/GNb/n2xz/1JwCAJ599wtuq4vwP/qLV6wAAjz/Emfx/+H8+49vDaRtLXRHhf7yGR/jFK+9e\nSodG+AWSjPgHOxS8uXgTSu5fypAw1tSwUHCxYP9Bj8T4RRah8S82kTBvj8l93T+4RfmSIV5gC67i\nYDbLki9R8RJAsOcUFf+ix+P2+BJxn7UN/C9fImHnv6CpxtsiEb6faiJ2e6qY4THF/EuOEecrM3p9\n8u5cYsR75N08CwU+j+pIhejTHjNi+N4gwycaCtn5FUpcgnFgmGPnM9lgHXnMdDovJmiPL+V5TSqr\nuP8F8+xvKyrWLOZe9griBS9f5D5z7oOjJF6mKqIV47ZXVfDvZgHR2NIW5wsmfYbJ51ddHfDRj87e\n5C4mJJPc/qguouICQjKZnNLzazovU1OCMeYuAHcBQCIRN709Vjes2nlvonH+B+tfv/oV3269xL4Y\nXXbt1d5WynPR6x0v7AUAfOwT13vbU49a5f7ND3E1lZJ4cXjuvq22z6uu8LaRk/yP07bnDgIA7v0e\nC8UOpfp9O5Oz/9AMZwa87SP/6xO+/Rdf+icAwOHDO70tVLL/yNfUcz9x8bIUidsXv4XN/LU2mOJ/\nfFcuty9TV/4u67INp/nFqNm9MMTi/I9kPMEvJqe6rBesqpJfMMPiH9+Sq5VcMNKbZV8CwuJloqGO\nXyBTOfuPuPTy5HL8D37IeSUqEvwPqvQSBa6SfKnoTSRfQoIXE3FMIsbtsPM+xeJ8+wZeLDmnUp7X\nsb7ZeiBjMT5GevD6MvYFNBrldUrl+MWK3EtGVVRWn+B7q9rNvzPNunjZvJ1TJs0vSx2md9yci4Xy\nVHswP/nSF4pyOxq2c+nv5vtRelXh1rdS3G/NtXxNGtwtUxDnMeDWTK5Nby/POfCwxsQ4g0a8gLrf\ncxEXR8KkfH61tlL5C6U4DZL2/5PnqPdkctRfhWKuMJ0A9OMYXctoMbT2j0KhuHCgzzCFQjEjmI5n\n6jkAq4loOewD6Fdhy3pMCAODEqwHI1ppv2CrYkwRZIfZk9B/YBcAYHDJOm87vnebb7/x9jcCAPbu\nZ6HuzQ8/CgD4o7/hpJy/+vSf+XbHsPU8JU7wnK66/kbfzsft3C65/jJvS+V4TisW25ir+mamHr/5\n1a/7drFov/qXLmDqMVFtvRLX3rzR2yIj7L14fNPdAIBXv+E93rZ3717fNs4709/HcVati+b7djpt\n5xcKsecoKrwnbStsvcuBnm4+p1TKt21JPmBogGO2As/WSzt3eVvzDdf59sF9uwEAq1au5XMS3pOK\nCntNK2uYUssJqqmQtbRRQYQKmZLwPIWtd6ilhWlqkxM0pds1JKioiKM5g/Ww/fCc0iP2nKsqeW0K\nBUGfDVnvSiQq7sFeXrP2w/be2XDjTd42nGKPTD5rr3NqhG1Z562LRPncinmmzLKuHRZeubDwjOXz\n9vh4XHgVo+wtpJAdMxRmz1JNDe/b2hR4ctmhMjDEFHBv2Pbf2cn3Y75g55TN8DxlvF8QxyXjpCgy\nioMFABSyZ1WVY7Zxxs8wxfkF9Ugpzhec9cuUMaZARL8N4BewoST/4mq9KRQKxXkPfYYpFIqZwrRi\npowxPwPwsxmai0KhUMwq9BmmUChmAuc8AH00COTCtA7tOgwAWLKEA69DxLRLZb2liHY+w6WSbnn3\nh337vv/4NgAgnefA7vd/7LcBAL986rC3JeIsfRCLNQMALrvyZm8bGWBa5oYN1j7YyQG3h09wTm/D\n/MUAgJ/df7+3XXsjZwMiZOe/oInpqZ0v2g/dvh6eUz7CNOG1N1vaqLqC6c7VK5gmzLvA6OZ53GdE\nUEGRsKW6qqqZvoqJTKtC0VJBFQuavG0kzZRgEATdPI9lKYZTNkPx0iuZ7jxyjENJgqB4I4K9jQj0\nLxRte2CYqSIviQEgHLZjRgwHMZcMB6PX1tr55dNMSVUm+PzCIXvOgn1C3lFmeUGjRQW9lnL0X18/\n9zk4wJmYQWZijKeB4wc5iaPg7F/+6y952zvey4zQC1ueAwA0zecMwvp6u6aSpisWeJ2Kbs2++bVv\neNs1G6717YamRrcfn0fjfP69VEbt+kVEqmMYHOw+mLALlBBrNzLCgeGdhy11nBcLGWRQyoQBSeEG\nmZoyYSA7wuvo11+so0KhUFzs0Np8CoVCoVAoFNOAvkwpFAqFQqFQTAOzS/MZAzgNoQWrlgMAjuzj\nbLxaIQx57PgpAEBLCwto/tff/41vZ42lAd/13z/kbf1OwPLAfi783VDP9Fg60wkA2LF9u7ctX7WC\np+cEGwfzp7zt1a/hLLaco0Cam5kSyxWZVlmyMKDnmMq55gabLbhnN89p7dXX+HaVo/yKxPRUTRNT\nckH3vd2czTcyyFlmwUj9nfxevO7SVWBY6rGuptpbqqs4IyygcNIZplhzWds+vPN5b9t/hK/T+z9g\nNcCGBaUmb6WUW6doiSnUSEhqStm5VgqdKJl5Vx11WkaVPOdYTIhZuuy1sMgoCyg7qQTU3c0UcKXL\n4pOilsUiz6nC0Z01VUzBxoU21/xaS989MczndPIkU59pp2B/op2zDk+e6AIALFux2tsiYaY2BwYt\nnXzp+ku87VQnX2cyMTcnXofMEFNqOUcThit4bVJD3O7tsfpTJsRrm83w/I2jY0tiHQK9MUnzJeJC\nQ8xdu3RWZGcK4d0gQ9IUlOdTKOYWyTLtcrbJtkvbGYz+MtMAU8+UQqFQKBQKxTQwywHoXEJjzWqr\nf3RC6ESVRBGx1mU20DYm3vdqq1i9Oet0fe7+1+9623t/8wMAgAO7dnhbWHxBX5q1ZV4aK9jzc+Cl\n/b692NXuW7Xscm9LC72dX/7clnTZeDuXi3n8kYd9+7677wMAvOvX2Vt2osuKWkXDPObydeyBO3zA\n1vOr6O3yNiMUsVdfYoPA65rYG9ZQx8HqgXNnQT1rOg3nWDOqutp5NUS5l8pqUdLEKV03i7WtqbNB\n+w/8hIP/m+cJbaugHiCx5yadYe2qQNfICB2ngrgOQakRIeaN2ipek7hTKU8Lpfc6Ue8Q7h6SOlFB\nTT1pkzXxAlV2GaBOwvtScEHYIyn2soTDvKb3/sxe21dvfI23nTrR6duZQesVjSbY67drmy3x1rac\nPYUjIuh9z0tWT0wGwt94yyt9+6c/vAcAcI3Q+Kqu54SKQIdKBoMPCS9T1AWoF7K8Jvmi9BA6z5RI\nWAiEzyNCOyqbFnpe7oYLlaQSO+8b1EBETBbeuUjQgal/pE91v4sc5bwT5TwV58Z7kZyg/XJBcoL2\nmdrOYMQy13mya3+xQD1TCoVCoVAoFNOAvkwpFAqFQqFQTANkzOzV7kwk4mbxklYAQPWCpQCAk/v3\n+O2VotRH/5ClW2pEsPSKFW2+feKUDRK/8VYu79GwaCUA4Ntf+LK3vfuDn/TtQ8ftWBlRBiQhgnuv\nvnYDAGDRUg56jwsuqq9vwM2NA8AffeRJ377jV37N7tfP5TnqaywtU0yxvtGD93Ah5TveZcvi7N7N\nwd6vuZVpxJyjpWqrWb8oUcHXLKC/qiuYpssXmZYZGbZz6e9h7ayVa9b49oL5ln4UTA8ijvc5KTSZ\ndu456NvRSjtmpsDv4tVC6yiXc5pPWab+EqLAcKD/1CCoyUQlU48B/TQ8zDRfPMozDILmTUnqI9n7\nJZNlGi8vCh0H97nUTJJnvX3bZgDAK65nnaeH7nvQt2Mlu77VIkkiJubffuAAAKC/n4PeR4bt/XL5\ntUzTPf3YMzznol2fq67mMTs6mO5tbbW/lb4+vp/mNy307UVttqycqBft6UyAKVz5Gy8Imi/YLq99\nyUXwR2S5GEERB4HpJLZHREHsYCw55gfvuHWLMYYrdV+gaCUyH53qzslzOJHzHsm5noACwMxdh4n6\nSU6yvcwRFyDll0wmp/T8Us+UQqFQKBQKxTSgL1MKhUKhUCgU08Cs0nzxeNwsXmypi7ZXXA8A2P4w\nZ8PV1DBtUrvUlm45tnOvt4UiPNfGekt7ZYWeTYwsVdTTc9Lb/s9dX/Ht9KB9d3zysU3etuYS1gCq\nb7E6UZz7BLTv4Gy/tksvBQDki0wlST2e/QfGZ2/tev4FAEBDPdOJS5ewttX2rY8BAN759vd5W1c3\nZ4mFYzYjq6qaabyIoHJqG6y9RWT7SSonSLSSJUW6epnya6i2lF1FvSgPMmCPzxqRjZdjeuzwAVtm\nJV4nytKIRQuopopK1lSSdGnYTSoe4zmN4ppC9rgBp5MEANW1QhvLaTWZ0vjMPJHAh1xGlFYZsvRb\nhSjbc+LYCd/uOW7LBqWyXG6l4xTrSK1deRUA4PgJvh/iooTPjq322lfJjNO0Hb++lilaI+rVdB60\n92lVHR9DIZ7f+utsVmnY8Pb5C5mCDlLvQpHx1B7AmY35/HhqDwCMK+EjbXDrGBXPhZKg9IJrGxb3\nYEyUywm2y+fKR95+28uP5iuH5AxN5IJC8iz2m+oxCkZylvqebJzJtl94UJpPoVAoFAqFYhYwqzpT\nRKxfEwQUjyqoKvRqjFOUvvbWjd628ykO3h0essHJdfX81d/VY4PSC8JjsflxVjtft9Z+6ecMB0Yf\nbedCxjX1VtuqGGOPSl5Iag8M2P4raxu8bd+u3b4dzlivRkgIg1c0WE9DrQgQ37V3p29X11nP0OOP\nc7Bz2/KVPKeo88BlOZh6WOgGHTqwz85t+VJvE44EGOd1iMfYiwQhAfTM00/YMZdyUeMS2fNIxNjb\nVSoI5XB3zTJDHCAuEXjBsimeZ0J4HcNO/2hkhBMBcgX2juTd9QuLyOp0iq9DImbbKeF5yuXs+sjA\n6LDQOgqKDWcy7HlqamUvT8H19eyDv/C25cuX8fE19qeybzsH4l97CweOL1li178U5jm3tVjbTnGP\nNNewXldPpQ0sHxpkD1wmzwroqzPWaxqLsVcuKzxnwbmaPK9NsUzRYgjPk/BBee+RXDO4Y4rC82SE\njlXcVdHOG+ENywpPqLs39CutDJITtC9qJMf8Hds+nU0xdSTH/J3JPieync32ixf6zFMoFAqFQqGY\nBvRlSqFQKBQKhWIamFWazxiDXC43yhYSFIMB0wX1i6yGTu8JplWIeHsmY+mIwUEOpq53xXz7RVB6\nXR0HCX/z2/8AAPjwxz7ubc87mkuOXxhhSq1aBFmXco5iyXGQcEUlUzCLlljNpu4OLpFjUq7obwMX\nXB7sYiqnKmIprRve+k5vixKTMYfabbB3c5Mo55LhcjG1tVbHasvTz3rbCllYt8Ke/1CJ6aGU0G+q\njVndooEB1pTq77daR/V1fK3iMaYpU2k7fnW1WBtRxiXudKQSdVz6JCvKuAwNDY2zSQQB9pJqkgiu\nU5WgTsOOjqUI30+pEZ5/t6PSImAazJCk/CzFe9vtb/a2jiMcbP7i1l0AgFe9gcvJ3Pfze3y7s8Ou\n32XXMkW7vduu89LVfD22PsXXaeFCSxd39fL9umoFJyeEQ5aaLOaYls7l+X6OROz24QzrUMVJlgpy\n5ymi8mWseVDoORIWFGvO2ipEkWlJDhZdceWIETpU8jfs+ixI6lChOOvA5XL25BS3T9bnRNsvZCQn\naJ/N8edi+8WLST1TRPQvRNRFRDuErZGIHiCife5vw+n6UCgUirmCPsMUCsW5xlRovm8CeOMY26cB\nPGSMWQ3gIfffCoVCcT7im9BnmEKhOIeYlOYzxjxGRG1jzG8DsNG1vwVgE4BPTdYXESHisn0Kjm2R\n2XwUYsos7TLFovWccRU6yvpLiYTbV8hk9Q1bqqUkMpru/8E3fPuDn/y/dpwc03g9J1lrqL/FUooH\n97K+UNP8Zt+et9jqUOWyw95WwVNGxmVaNS3kkh/Lllm9rJzQ3bn82st9u+OQzfR67qnHvW3JkuW+\n3Trfnr8RmY79PZwFV+NovpWCSoommKIpFey5poeYxuvr5uyxtlVWEyudFSV24jbzTuoPZfNMidU7\nbasjB46xrZk/7Btc9llIlLUpifNPp+2cpBaRbGcC/SRB842M8Pg1NZZe7O3hc4rHbYagzHyTCmrx\niN0eFpRWNBIfty+JEjmrL7nUtx995C4AQGNjk7fNE5mkt73pDgDAQ/cy9bd01VoAwGXrLuGJiDX9\nzr983fbZzBTwG25/m2//8Hv/AQC49LIr+XBxVpGIPdfDB5lWXrGKacZgLUriOlCIM1U7j7vjBCVX\n6ajbfIF/I0H5HwCIFAKNMKZ4iyLTM9AACxuRMjrHmMlnmGK2kZylYy5GJCdon+kxE/VTrs+p2s5v\nnE2pm7ONmVpgjAk0BU4CWDDRjkT0EQAfAYBI5Px5wCoUipc1pvQMk8+vulmamEKhuPAw7QB0Y4wh\nogll1I0xdwG4C7CFjo1jFrOpwNPAngASga6lgit0XM+B1xIxVzh3WASL59L2C7mxgR9785rYs/St\nL3wOALDy8pu9LW/Yk7FryzYAwIp167zt6CH+6q93WknHuw5729Il7BGKu4DoDhE0H8vbL/WG+Xwe\nB/ce8O1Vy2zg8913c/HjSz/CnoyTJ44AAJoXsY5UqcTB3r09Nvi4Iiy9D3xZdx2wYSJVIfZW9Z4S\nxXSXW2/b8WPsjatI2CDmugb2vPSdOuLb216wAfRLl7EOU6AwDgDVA3asWIS9ODLYPEhCyAubEbdQ\nxM0/J6OlBfJOCykiPUvOsyVVzyE8WwWnAk4hfqEvSs+YG6t5mQj07z3l269/4+0AgOERDhZ/7jku\nTn3H+95utw/w/biyzV7HF7Zu5TGLPL+FC+29ecOrb/G2Y0f5Orz1Xe8BAAwNsCfxmLhOMeetXLqM\n742hIU7IMCW7jlU1/HvIDnHyw8G9NsD+pls2eFs8Yfd95KH7ve26G1lPK5ux995gkecUJV7n+S02\ncWRwhL235ztO9wyTz6/W0zznzhjJMX8V00RyElu57YqpITlB+3S209lnBoH3qLwXKTlB+8z6nrj/\n8ThbaYROImoBAPe3a5L9FQqF4nyCPsMUCsWM4Wxfpu4BcKdr3wng7pmZjkKhUMwK9BmmUChmDJPS\nfET0HdhxF9DQAAAgAElEQVRAzWYiOgbgswD+CsD3iehDANoBvGdKoxmDkKOoSj7mVRReFe92QfBx\nSDjW4zGebtH1k8lw4HTI9ZlOsY7Sqe5u3044Wqin3WdIo7mNabrNz9oyL6k8UxjFAgfsHjhog8Wr\nazjYuqOTNX6GdtvtG25i2qboAnkpwud5xXVX+XadY51qZBkUIwoAu/U50s4Fnw8dYOrxmistBbNl\n6wvetuvZbb79jg/YS9M9yNpUBcFW9PVbe0M9n1M0bqnP+37+Q2975Q18TktdgLzJM91YJ3SwAi2i\nzk6myQqCsis6LSPBuI2i3Eohu284zGsii/UGSQuFAl/nQmH8rSyTGwLKryBoumJJlMNx5VFML8+j\nR+iBGXK6Zv1MZ77+9rf49v132zI0r3sbr9P6V9jkgx/8O1+bBc1MfUZdWZ0DO/d42xvf/g7fbj9o\nabhjRzjQHyIRoa/L3qfDwzynRAWX7Ym6APXhfr6fewb5mqxca5MPCkW+jql++3sJ9MsA4KXtXA6n\nlLLrt3A5B80vWca/ocEhO9ZTj7N+21xjRp9hM43kBG3FDCA5hbZiYiSnud9kx5fbPvVjph4kPr1x\npoqpZPO9b4JNrz3j0RQKhWKWoc8whUJxrjGrCuggAgVf40/Zr/VojL+0qyrZI5OH9UoUChywWygK\nr4JLx07EOQg58FItW7PW2zoOH/btEWNT6WvqOBi74wB7BZa12WDw7m5OuY9E2DNV12i9L0Wh4m5E\nUeXLr7HFgl/YwjIHbcvtV3tnx0lvq5/PXqBfPPQQAKBUyR6Fkyc4QD3vCgDv2v2itzXOZ+/GYMp6\nxrY9vcXb3n3nr/l2tMIGky8XnqP2vft8e57zQAym2cP3lc//FQDg/R/7TW9raORkp7QL8o4LCYai\n8Byli9bb1dvNXrv6Rj7nQqCLIbySoZBQ0XYepVxOBNWTVNy2x8v49Ky7JtGISGgQBXoDT6f0gIVG\nVYS29rxQC6+sZYX1znbrsalv4ISFwUHu6/WvuRUAsOuFXd721S9+DQBQJTyZg4McmL1yzXoAQO8g\nh+u88NRTvn3tTdfZeQhvU0Utt4f7rEdq0wMPe9ub332Hbx84YO+jzmN871WIvva/ZO+pQ2F+DJDz\nZl1yGXubKuS9ecwmwEXi/Ft95gn2Qq2/2so4NAu5B4Xi3CF5ltvGbp9s3wsdyTF/z4cxJ9s+dr/T\ntU93zOntZxNsXg5am0+hUCgUCoViGtCXKYVCoVAoFIppYFZpPgIQdszI1W94NQBgz+NP+u25HAfC\nwimg9wlqTypye3Vnw9uzTn9o744d4/aT7dQwUy0BrQEApUFLm0REoeRSlnWD0k7DJ51l+urmm7jw\n7dHdlj7b/QKPv2JhGwCgbeVib0sJbaz58ywFtOQS1vKpbGJqseuQpZeuuOYGbzt1qsO3H/r+vQCA\nd3/gA952cO9O326c3woAaKpr9LaC4XV+4nGrJ3T9ta/ytjt/538AAE6eZHqoWGBKrGm+pXBOHOPA\n6HkLmAaMR+2aJiqZgi3JNXU0nwx8lgroYUfVjZb1oXH7RiKCnnKUXSYvEhpEYeyoow4lXVgQwdxk\nLF0bDvPan+rhYO2qKntORRHo/spbWA+svd0q6T+6iSmvpctXjTsPEtpX+ZylVlet5OLGUcPK4h1H\nbZ+NC1q9bd9eDgaf56jbZWtZ9bzjBFOGASUXFvf4gQN8b9RUWJr2wK7N3tbcZufS08P9vONXOOTo\noRctpfjmt79dnAefU8r9XiqqmSJVlEFyridwsSE59T2Twd+pH3PxIDlBe6b6PJvxJzq+nH2qY5Ub\nZ4I9Z0inSj1TCoVCoVAoFNOAvkwpFAqFQqFQTAOzSvOVjEE657LfRiyllhblP/IyW8+V0EhVMl0g\ns7MyWXucpAaDjK3rNjJltfeF7b7d12dpuqwo6rtoMdNT2ZLNfDNZ7jMcZ9qnqt7SIr1CP2nbi0yR\nLFts6ZYrNjAld99DlobrOcoFlectEOVuFtiiyD/55le97V2/8RHf/tn3rdZTASme81IuhPzm974X\nAPDd7/+bt935G3f69vCIXadvf/9r3vbO17zXt0+MWArqxQP7vW2tK368aiVnDRqRbRdxGYbz5vHa\nFQoitc5lOIaJb6+cKIYboCgyIaUOVcQENJ/Q3gqPr+uYz/K9E9TyLYnvA0kDZrN2LJHsN6qczdCg\nvTcKotzLoX2s7dW61JZJyfby9u/8G6/5wLDVpPrEJz/pbSfabZ9F4nEuWXuZb/918v8AAG5/823e\nlqpkSrC/3ZaOubaGr4MstNzfZ7MmD7102Nt6avnebFpk6di+k1wgfN26q337sMtkXX/9dd4WaHz1\nnuTC0g/ed59vZ4bsmEMjnPE61Mc6V/0n7blmQ0LD6+WC5FxP4OWC5ATtKR79MqH3ZipLbRozmIZt\nJnE2/Z/5MeqZUigUCoVCoZgGSAb+nmvE4zHT0mI9MYsusVpQh3ewLk+bKJy775AtFmxEQLH0JARB\nvcaw9yLwTLUs5WDv/Ah/Yff1W0/BojVrvO3gDg7IjUWtJ6Mk1mT+okU8f6fJ1CzUwgtCXynvoutT\nvRzgfutbbaDuU09yoP3hl1gRO9Nvv/Df9K53e9uxDg7+NSXrCRkZ5AK269dxsPr+Qzbo/U3vfJO3\n3fXFL/n2da/YCAC48ib2PuzZwzpTlS4Ied481gVqnmeD1fM5PjcIz1TJeaHE0qNUEgHkzouUFcH7\n0rNknPy9VEDPF9gbGHUeJemZkggSEcKh6Lht0rsZE56pUz3Wc1RXw5pJQ2JNX3zB6nTV1bN+UiHP\nAfS3vO6VAICRIfZqhsX9+I2vWs/fq17zam+79IrLAQC7d7FG2Kb7WRNq6WIbWL5oCXsawwkOFr/0\ncutF2r+XfyPNC1gvrK7WXrujR1ipfd+el3z72hvsfRKJVHjbD/71m759+WXWS9ZxkhMauk9Zb9iS\npRwUXyU0yo65wt9LVyzxtgJfZlyyzmpn9fVyn1//4ue3GGNegQscrUTmo8F/JOdwIi9LJOd6Auc5\nkuMt401jPFRldpj22Oe6/5mHXJJyHrxkMjml55d6phQKhUKhUCimAX2ZUigUCoVCoZgGZpXmq6qu\nMpdedikAYGTYcgOdHRyYXRBUT1De47a3cjHZXz740Lg+M4JKCs5l/nymJYYHRWmYqOOViOmhXJYD\nZYOAZRkUXxS0UX1zs537ENN4UVF8Oe7olDpBxdS48h/VC5kabGhgzadTBy1tcryDqZrGxhY+QbKB\n5wWhT3RoKxcyvn7DRgBASZRmmd/GFExQ0qW+sd7bEgmmr+Y12XOKV3NpmEjUbh8WelyJGB+TTlvq\nNBplW1FoVwWUXjkKFuA1LU5w70XLBJvL4wMqT9KAwXYCH3vqFAdj11a7cxLXrusU62g11tjz7+rg\nY0yEz2ndZbZMSlyUUZH1bDbdawsdv/QSJzx8/HOfAQDs2My23i5RVqjO3hMDolBx2zLWrlroriMJ\nvazhQaat8xl778er+No98vADPNZRe09VVPOcFy5Z6tt7X3oeABATeSiVNXadqgWV3dfHv6GYu8+q\nmlj76paNN/LxFfaaHD9w3Nv++ctfuDhovlYyH/3o5PsppovkXE/gAkGyTLuc7Uz7mg64n4AyO7Pg\n95max5kgWabNNqX5FAqFQqFQKGYB+jKlUCgUCoVCMQ3MKs1XXV1lLnM0X0eXLZOSEtlRBkJnylF+\nkQRTFKUcZ0+FXSmQbBmaDxPoE9XVWcrtkmtYa+c5Uf4j6rL5JLU332UfAkB3l6WAcjmmAWFkqRA7\nVqXQxko5LaRFS5i6GxjmOddWWGqwV+j2QGgdFVJ2fdZfwXPOisy6G2+xFMvD997vbQsW81ixqF0/\nEjTgyDBrVrWttVmVzQv4PAOar6+Hs91q65kmNMb2Jde+oqJCbLdrUizy2giWzrNjIZGNF/Qp95XU\nnlznYqBDJe4Xf53Ftc9k+N6Kuv6HRgRFG+Xx+05ZSixf5Otwqovpt4Fhq3v2lre8i209A759349/\nbPvpZZpw4WJL9/b0MYV79VWcibl9u83qvO3N7+A5DzPtnMnZdnc3ly+qb2KKOKBRm5pYe6qmsta3\nn3jU3turL1ntbVniax/O299YJsVjRkP2+CPHD3pboci/u16nWfXqN7zZ2/J5ph4bm6322IM//bm3\n7drypNJ8irNEcszfiba/3JGc5n5TPX4m+5zu9ulg6mMnk1CaT6FQKBQKheJcY1YV0LO5AtqPWo9U\nPGo9Bc3z+at64cJm396zy34ZhyPsaRhK8xdw1HlcZPHjwJOxcDFrQ3V3smZTzqlgb36UvVERUew2\n4TR+8kI7anhkyLcDD0AqxV/30ktFEevpqBZaRiMnbID90YPt3gbhhUmV0VSqb2Yv0aLVVwAA1jnN\nIgA4fvKob2956inXYg9cMcUemYxT1G6q56D4EyLYfbDfeldGq5lbj0VlbY2wCa9hcXxRYLlm/pqU\n2JYTDtDgXEsYr4oOAJHAIyXWJCI8jCW3fiQdV25MKvEx6X72uHQMWo/KKRF0TkI9v6XNapzt3cnF\nm2WA/RVXWk2m9v18HfMhvh+XrLVaUZ2bDntbb6cdKxRnT+VTjz7m2+/76AcBALuESv+8Vg4QL6bt\n+kTDfL+0iKLHzrGEqEgo2LmV+9pwk/WCPbrpcW8jcZ0Gs9aL9vHf+wNv+8l/3g0A6DpyxNsaGliD\nLBGzHsrm+eypzOc4AD7rPLHNdazyr1CcPZJzPYHzGMlp7nsmx5+uz2QZ25nM4+LApJ4pIlpCRI8Q\n0UtEtJOIPu7sjUT0ABHtc38bJutLoVAoZhP6/FIoFLOBqdB8BQCfMMasA7ABwG8R0ToAnwbwkDFm\nNYCH3H8rFArF+QR9fikUinOOSWk+Y0wHgA7XHiKiXQAWAXgbgI1ut28B2ATgU6friwgIuRFHXPmR\nlNACKgjKrK7J0gRB0DgAHNzHtEqgdRQWQcrhGkundIvCrrLYre97HlOL3SeY9gkF+kiCP7piA2vo\nbHvkUQCjg60rKqp8u+jmIphHVNRZ6rK5lanHE+1MoYTyloqqauTA4rpmDiCva7H03P72Q95WK4KQ\nlzpKcFs300ed3SLA3Z3r4sVinqLQczhu12f7dqaHVq251E2OqbVIRGo/2fMsSopVVH4JKMFolI8J\nyTrIwXEyeF9QekECQDgsStiUZNsdI0rYGLf2PcdZt4yY/cISp68UFdRkZ2+3b299xpaTuem1XHT4\nePsBsd0Giy8U1zEkTiqcD9aU57RwqaXkOg4xLZvL8j289Wk7pqSNe4e4dEzngcMAgOXXMMUr9z3u\n7vMVbVyOJlLNa37P9yxlV7OQKbcV6zgYffNjVgvqq3/7ZW9btd7qXEXjvN5Ni5nmy6WtfaiHz+Pg\nQS6SvWiVXedLNnBB58cf5mD02cZMPr8U5zOSE7QvNiRn+bgz7XO640z3+LnDGQWgE1EbgKsBPANg\ngXtQAcBJAAsmOEyhUCjmHPr8UigU5wpTfpkiomoA/wXgfxtjBuU2Y3Phy2osENFHiGgzEW0uCckB\nhUKhmC3MxPNLOAUVCoViFKaUzUdEUdgH0b8bY37ozJ1E1GKM6SCiFgBd5Y41xtwF4C4AqKquNi2t\nlpY66rKFZEbW0BDr9sRylqNZvJQpr+tuut63f7npaddiqsWkLU3Y0MCxpEOinIwx9mWutpYzkQYE\nzRhsl1TKc/c/6NvRSMhtZ62i6hoeK+J0qiJR1sZqa7HzT2V5noUi02wtrvRNKcbU4apLL/Xt4ycs\nvbdoMZeI2frYkzxmtT0uJvS4akRf7fssVdXUxFli2SJnsfV2WQ2jBYt4e1+fvQ71zUwnlgSllnUZ\nYYkYU0okLmTUUYK5gtQF4329DlVBanQJHtChIKi9uKD8AjoWYUkj2jlViwxEeR0HRmy7aSFTVkUx\n57Zldn0P7WHKqrqes/AC3bOuo6y/hBgfv3CppdpKhj8Y9u7Ybcds4Xv41puYNt6xbQcA4KbbXu9t\nhTRT3akBq3O1cB5nYhrRf22tzaKT5Wb27djp22uuXAkAyGSYkhs4ybT2a998OwDg+CGmkF981pYq\nWrSay9qk0pwV2e8yQYeWcFZhbR1TyINddjvFBO87x5ip51drK82eKJ9iikiO+XsxIVmmnRy31+nt\n5wOSk9gn2n5hYSrZfATg6wB2GWO+KDbdA+BO174TwN0zPz2FQqE4e+jzS6FQzAam4pm6GcCvAXiR\niLY62x8C+CsA3yeiDwFoB/CeSXsiAM5rUXCaT3ERpJwWitV5J6LzggsMBsoHKYfEx2LIBZtL5Wv5\nKRl4R4b7Wdk6GAcAapw+VKXwXOWFFyflNJlisRiPGeU5VVdYe6A3BXCh5TXrr/S2I/t2+/b8RfYL\n/9KrNvD2o+wpiIZsnzu3vehtdQs4vGPdeuvFOniQg6WP7N/n21XVdW5OfB4FUdw5UWm9WJmUYD7c\nmhYy7HHICz2uIKhfanzl8+yFIrfOMoBcvrWHXGB7McxzKkp1e6dMHhKFknNCsyrwQonDUSLbZ0xo\nLh1uZ02oS9bYwOtQnG/52lpWC+85YT2UQwOswdXT2eHbb3znWwEAv3zkaW+T57ztl9be2srB4Efb\nDwMABjrYG3RMFLm+ZJ0N0g4T9/P8Vr7fa5zn6cXnN3tbXQ0fXz/PetnmN7F3tE5oQi1dar2NP/7u\nD70tVOIrEVyH5Wt4zgf3Ws/bqVN87gNH+PdiIja5YSTD6vjdx9hTu2e/vU+XtS3GeYKZe34pzmMk\np2i7UJEc8/dMt88lktPcfi4w82NOJZvvCdjXoHJ47cxOR6FQKGYO+vxSKBSzAS0no1AoFAqFQjEN\nzGo5GWMM8vkgwDYoSszbE4KiSTgtp0yaNZNkQdWgcK+Ii0Y+b/fNC72qRFyIDTmaMFTFAdqRiCyJ\nYumWBQu5nMvx48d9O6CtgrIzANAldKr6Y3Y5r7qeayLuPWAD7ffvecnbilmmRQ4ctbpI0Rqm6eI8\nPZQcpVUU1Fz1fKZyjnXa4w/vZuoQIvB7xB3/4pNcQqeQY8ps90s2YHmhOOd42AazVyY4ALumUWgN\nufWNldHwAoCIC+wuitIlBWJKMCgXExIXLxSTfblyM4Lag2w6e17QjJGIvSayOHJbGwftd/RYGm/g\nJNNXJ05wu86d36p1a7wtK4LBv/eNfwUA3PKaW71tWAS4Vzi6+vDRvXwWITvPgij1c+mVrL902CUH\nbP/5Vm+75joOUH9pl7VffhkXR9789DO+vXzdKgDA7l0cdN4tdLaeGbbUbW0dX0dZ1LjzhL23T3by\nPb5q3QoAwD5R/uj172TtrV/85GcAgB0vsB7WvGbW3lq10q759bey02fLY6yBplDMHpITtC8UJKdo\nU5wPUM+UQqFQKBQKxTSgL1MKhUKhUCgU08Cs0nxE5LOtgmy8eIwpiHRGaOyMWDoi0NIBgL4+pq8A\nu2+9KDezeLHLIBJlUIaGh3z7+FFLZ+RzTO/E40zzkcsIO3GMaY+qSp5fkDyWyzL1KDP7gvIpm5/k\njK/6Bpt5FxZZf1FBj61ZauccCjGFOdLLaWp9fTa7rKqGS+BEKznLrn2npVvmL2Ito5PHj/G+Lgtv\nwWLWBeruYm2tumrbFxWYRwsyuSoaeW2ldlbYUacFkekYEdl++YJdn5DgcENlMjFH0Xhi31Kp4ObO\n6yQzOQsu21BStDD2mP5evt6D/VwuZskym9l25KU+b5s/v9m3q6rsOjSKUkP7dzFl96Z3vRMAkBYl\naIygSy9/hc2qrJvHmaCbTvwEABCKMZ25ezvTvSOOll55GZd4OXqQMzmNy2Y8uIspteaFPOf9L+4B\nAITjfA/WNnNm3+ApO9eWRaxT1S4yHCMJu74bXnmDtx3YZ0vfVFVypuP2bTyngvsVXHUF05F79nAG\nYihqz/Wn3/9PKBSK6SA5QVtxPkI9UwqFQqFQKBTTwKx6porFIgadVlPgqZBaPVLNPNCEyssg5gJ7\nrgJPxfAwB3N3Ol2gkRH2HC0TRWAbGqzm0tAQB+EW8zxm3HmmlizhwOVDQh26qsJ6ZEJCeTsaYq9D\nMGdZCDldsJpXkV72iBhR4PfIUespWLZynbe1Hz3M+7pzvulVHPi8ZTMHIS9Zbc8vJPrs6mDPWqB2\n3r6XA9xDEfbyXLPhZrt9P2+vdx6pXIq9PGhkjw25wO+wULk2IkLcOYm87hcAlIQXK+yqXZNYx0KB\ntwcFjIuiT+mZCrmqyqYo1O/dvXPkACuYhyC0tVqsh7C5lTW6ElWcnNDZYQWwn/vmN3ieInlh327r\nUWqsY52nqgb23ux83h5/9Ch7BUtu/ibH63DNBtYTe/DHPwIAHBvidW5dutK34xl7H3Uc5cLY0Rx7\nai+/0hZAPtXFnlZTyXOubFsGACjkee3Sg/x7CbfYeT3xEAeIR6usJzYm1nvZci6UfOyY+92GhRc5\nw7+3cM6tuRFeQ4VCMUUk53oCirOEeqYUCoVCoVAopgF9mVIoFAqFQqGYBmZdZyrrdKYCqouELlBJ\n6EMFNKCkf0ql8VRPokLoSLkg5qIIbE4Nc5mUQJYooPsAIJeX+1oKJF1i2iIi5seB0zxiQQRuB8Vw\no4IeyrvSNl0jojhyFQeQp4ct5Xjk8B4+CxHgXtdoA46feuh+b2tp5WDyjnZLQ65ayYVp0ympx+W0\ntYSeV1Foc7205Tk75woZ6G8pyZvWbPQ2SanF623Ac0FQpLKsD0WDayeup3htz7kCx2GxjqMKHQc6\nVKJPY8RYxm43Yd6ednpkbSvbvK1C0HAVjlpsFQWji6KUUH/YnvONr2NNpYZKpjZ3uTIpyPE8du3Y\n7tvXOX0oOsaUXCCC9vp3v9Gb7v3ed3w7UWGvLRm+3jtfeNa3W5damu7SK67wtuaFTFMiau+zLU89\n7k25NF/7+a4Y8VA/09pShysWte36Jk5e2L/D0qRVjfwbCcf43ljkCpWHxdrnBM23/gqr03X88FEo\nFHOL5FxP4CyQPMvtkx2nONdQz5RCoVAoFArFNKAvUwqFQqFQKBTTwKzSfOFwBHUNVgdnqNPqJwXU\nGQAY8W6XcVRXUCYEGE31BJRfLCpPIdAf4iyxVF6Wo7GZg5k0Z081LGDaJNCUat9z0NuiUalDFXI2\npvHq57OGz1CPpYpMSWYl2uML2Yy3yWy/ecttNt7xg4fZ1sLlOYwroROvYr2roAwJACxfb2mV9iNs\nC4vMvoKjVWXplUqhzdXoaMTBDNOQC50m1cH9XKZk7fqrfTviLlNYZAVCUIdFRy1K7SlJLxmXASmv\nfaDxBQARN0BRdCqSJuGzPgX12OW0tWQG3+Bgj28vdhma27ds9rb+Pt7e19ULAGhsYp0mqVEWMMc3\nveY13rbj+Rd8e+dW229NNVOLJbfm9/3oXm+79Q2v9+0tT20DAERifI9ddtV1vj3PZR52HONsvaU1\nnO0XitrfxmXXcIbgMw//gvu6+ioAwKM/fdjb5Jp2HLNUXCbL1zFeZfscHhrwtqOHOTs0nbG/oaZm\n1ruqaeAMx5MdtrzSqQHW41Io5gbJCdrnI5LTsCnOB6hnSqFQKBQKhWIamFXPVD6fQ5crxBpoMsGw\nd6JUZM2piNMoqhAB5ilRWDbwGBWliLbzWBREUHleFKsl57EJh7nPvk72TixaZj0yt9xyvbftOXhU\n7GuVw41h78epTv4Cr4pH3Hb2suRdgHpMqLIXhLbWsQPWo1QSgewjA6xQHg7ZuWZEEPGV11zp20ec\nynX/MS5wWxBenFDCKZeLoPb0APe1a+cOAMDCVg5CThvb5/qreR1kAHmgXB4SCuVSFT54Rx8V9C4u\nVOB5kgkFUalZ5RxOMdFBXCjNwwWmH9jNQfsF51mLRThYWl6nZ3/5JABg3jz2JGaE4n5do3Fz5jHD\nMb5P1q62Af57X2DPVt0C9mLVNtp+T+wROlcuUP7yq/h6bX7iSd+uqbFB3lfcerO3tb/ABatPnbTH\n53PsJQoKUwPAmlVr3DmxN6wg1nnn87ZQ8lU3XONtj93HnqsRl/Bx5Q18nY+5wtvr1671tn279/l2\nz8l+AEDrCr5fKp4WF9oVdX6dCOT/9wNfg0Ix+0jO9QSmieRcT0BxBlDPlEKhUCgUCsU0oC9TCoVC\noVAoFNPArNJ8KBmYQAPJBefGRPmLkRQHaVc6LabiKB5PlA9x9GA6w7o6CUdpyVhlSduYsCtDUmL6\np0jc/8njtiTIkYNcDLZpAdNClzm65vnnmOqRZU7yGUtxVDUu9LaKCktP5U9xmZG81M5yxWyN0FQ6\ndYpLz8xrssG9FfWsTXW0nfuqaLD2bC0HqJf6pbaWo+REoH62wGsWLVn7sSNMZ7attkHOvd293rZE\n9J+IJ4LOvS1czUH1xlGWUsMrQkJPLChHw8wnSrI0jKP3ZKHjjKBGg0LRtbWsA7V4qQ0w3ya0n+IR\noffl1nzbZi7KOzzI6xzMLyJK4NQu4CDrihp7fie7+ZisCFDv67D0mNRNC3SyegSV3N/N7QAn9rE2\n1YkOvraxbns/1jWx5lNE/AaO7rU05759THca4u2H9x+220Wh5JBICgi767B3xw5va6m353zsyGFv\nmyeSNE6222D0xx94kM+ph6nuepdgsuX5bWNPU3GBYGMZemnTBUk5JSdon49IjvmruNAwqWeKiBJE\n9CwRbSOinUT0OWdvJKIHiGif+9swWV8KhUIxm9Dnl0KhmA1MhebLAniNMeZKAFcBeCMRbQDwaQAP\nGWNWA3jI/bdCoVCcT9Dnl0KhOOeYlOYztu5LIEIUdf8zAN4GYKOzfwvAJgCfmnREV9bDs06l8Vlc\nABB2lFy/yGKTWkRFRwvFRemWgNKT1OCwyACMOz2fgqCUSNBPQbag1InqPH7St08csRRHWOgCGZGF\nl3PZUXVCm6rkKCtxmiChg+UqemBwkHWe5i/gcjERpy/VK+ghI8rutDhdJFnSI5UaT30GelMAEBHr\nGF04c94AACAASURBVJTgCQnqs+u41TVa2rbM26pECZ6wy0wsCj0rPmOg4PqsSvC1kZpUphi0BYVr\nJIVr+w/HxLu+oPmKbq5xkenZftjSY7WV9d627dknxKxsn6lhvp9KohxO3g2VzzHVnDrE1OcxQf2K\nSftWRdSuc7EotdBKziZK7QhaeDhl53LZ5eu87cRh1gszUXtcQwPTmYsWsQbZ/ffazLysyKQsyVpB\nxl7zsPhmMmJ7IbjPRQma3pi9DxujvI6hKB+TcHRuTwdnjw70MfU54LTWXv/WN3nb7ueew1xhxp9f\nCoVCUQZTCkAnojARbQXQBeABY8wzABYYYwI1wZMAFkxw7EeIaDMRbS7JonYKhUIxC5ip55f4LlMo\nFIpRmFIAurHR3lcRUT2AHxHRZWO2GyIyExx7F4C7ACAajZogiDyXtZ6GfF4EJgvNqaEh+9VeGKWS\nLQsde6O35Zz3ItAxsvvx9lTaPg0DVfKxCDxa0ajwHAkvU+CxKok+WxaxF+mqq6yezyNPszJ2qWC9\nBmHwMYkoayb1DPa70+A519ZxsHm82uomZYfZc5UVHqFsLweJB4gJz1ngkSoZ6R3hffNue1gETgfr\nt2/PXj63617h2739dkxZBDpRyXOOxuz6xSJinUVgdDRh7UbMydD49/psgT0uCWIvVJB8UDmPw1w6\nOmwQdy7NnqWWZSt8u+gC7TuPs7dKqrIH2l91jdznsFjzkHMtyg+CqPDwZbLs3QkQ7HuinRX1ZYB6\nxHnWdmxhz016kJMHFi+3nsFVq/g87ruXA7+zRbs+RiQ0hERUf+C1zUhvnCgCDufNbFvFxZ+7T9jx\n95x4yduKW3lNyXklaxrZQ3bJ+kt9u+OA9RDeeP213vadr34Dc4mZen61tpbfR6FQnF8ol0QBcCLF\nZNvPBmckjWCM6QfwCIA3AugkohYAcH+7znoWCoVCcY6hzy+FQnGuMJVsvnnuiw5EVAHgNgC7AdwD\n4E63250A7j5Xk1QoFIqzgT6/FArFbGAqNF8LgG+Rjf4OAfi+MeZeInoKwPeJ6EMA2gG8ZyoDFguW\n+kilLcUgabRCQQbvWmoiFJKFjtnLXnLvgfFRxxdGjQEA+ZygQBwtIwPMJdUTtEOCvgnoSIAD4AsF\nth09ykVoT/Y8AACoqmNtqkB7SgYG9/ZwwO4rX28L5x7YyWVECjmmYlrnzQMAHNt72NvkK3DJRbCP\nDLLmkaRDy9oMt0ulYF4iANwFi7et4qK6HR1c7Na4ejUrVq/yNhn0HxRylnWQE6JQc8gFm8uEgryg\nnxrrbPBzUQSoi7huT8mN9DEllnf3U+sipqx27+Y1DbuC2aNWRgbQO+pRliySg3oqTRxTFNWXg+sr\n19nH1AvqrSASFkyvpREP7GYacGSE6cJf++/vAwD8+R99mbdnREJGyPVV5Htc/kZS7pqERtHj43/y\nxZKgO7P2PipmhRaaWHtyJ3VoJwfkh0JHxb52+2f+92fGjTNHmNHnl0JxbpCc6wm8LDARvXf67ac/\nJsBUsvm2A7i6jL0HwGunNIpCoVDMAfT5pVAoZgNaTkahUCgUCoViGpjVcjKxWAxtLkOps7MTAJAR\nGjfFImds1ddbWmhggGmNsKBLgsy/bF7ScDRq29h22GWMyZQcmeUW0EdSuyqdyYi9bV/VLsMOAEZE\nxldx0FIjw4OHeE6u+0iYqZaCoPw6Oq2OlRGZa6dchh8AHD1us6NuevVGbzt+cL9vHzl02J6byOAr\n5nhNgvOTVE8JUqIimIvITHPaXn3dnd524yv44752YQsAICHGrKzkcjIxn80nMtfEtQuFnN6X4e2x\nONO5Iddvn9DWGu4fEMfb40518fzWrV0NAPj6N/7D23J5puwq3TWNxctncho3J6kbJqnL4D6S5Wbk\n9qLLVgxLmSe3tqKCCwp5UcrI9dnTzVpmoRjfe3/6ub+1toTILi3y+IVgTVPyN8ATCAXXVmRKGkHx\nFl024JHdTNnVzKu12wZ47WT5Jf8bK0ldsPG0srkY8946cH5X/UjOTDdnldE0Q2Mrzm9MRpNNdu8k\nk+XbFwPUM6VQKBQKhUIxDcyqZypRkcCa9WsBAM2ugHC18GjsErpGx49Yj4z0HEWlZ8p94Ut9JNaJ\nYi9HqciepbArnBuSAuCG/yPidJHkd7YM6IWxYw4OcAA5Cc2pQOZcBtWXikFQfHkV7L1btgIAqutZ\nYTydYbXywPvzzKObvG2onz1XNbXWk2BKIhhaeA2KQeD0KM+QWDN3fvKYUtHpdQnZ9oMn2HtyzTyr\nb9g/yN6iSIxvpXnNNoA8FhbeCxFsfqjdepQOCYXxkLgowVTXOm8TACxd1OLb+ay9pr1V7CH8x29Z\nj1TDPNZerG/iQsVdTlk8K3So4kIbK/BKZrO89gSZqOCSF8TahUPiOmetJ2eUnpf7m8vJAHERoO73\nZVttLSuPIzTesxQRXtPcoPXc0ah7dLzCOQkPoSmWSajIs3d4/eU3AwB6jrOeVb6Ml0nqoo3KbShz\nThclkmP+ng9ITtE2W2PP5viTIjlBW6GYGahnSqFQKBQKhWIa0JcphUKhUCgUimlgVmm+QrGAnn5L\nkcVjloorCCpl8VIuUdHebikgSRbcfNNNvv3cc89MOE4uK4PGhS6Qo9yMCLYulQSt4/iKKhFgHgpz\neZGoo0t6RQmX0YG4ti2LCvt+BD3U1Mz003xHX+3eweU7pHbWijXrAQA7X+ASNTJAPgjgl2VERukn\nub5GBdqLwOmAlpEB4hFXHDlSxTRYWpQkiVfaaxeLsHZUVugStR876fqUelY8Zihsj1/UttjbBvt4\nTaOOju3qYGpxcFiU2HE07v6jx7ytvtnSe0VB0508sM+3wxX2mNr6ed42PChL8di5FgqidIoM2g/u\nHaHpJK+pX/NRWmhuP8j1lkW2ydn4mOGB3tNuj8eZFocLYJcsnJxTyZ1TURRCDotrEpxeUdzDz2x6\n2I1ZHLcfxGhybQqinE2QJCLP86JG8gzts43kFG3nevzZHLMs5nwC4zEqGnuuJnHuMVGgeWC/WALR\n1TOlUCgUCoVCMQ3MqmcqM5LGri3bAfCXb08vB1MvXMjK4T7FXHhMqhvZY7TmMlurNJdjT0RPhw1s\n7hngPvMi4Dj4wpdOHOmRCbYbmV4uMukD70RNDXtJSlXsKciesl63tJB7CHqSHoN4NXt0Kuts4Hlj\ny0Jvy6X4S3/7c7YI7hpRTFZ6sYL5lyYoCJ13gdWjvCxlFOBlmn9QGPf40SPetmpVm2/XtlgvUDbN\na58TEhL9vTYweuHSpd5WIaQPYi6YW6qeGyFxEUgK9PdygPvACCu8N7tixLffdqu3bd9qkxf6siyn\nULOAi1AP9lovV/8pLsGWcB44AMhkbAB5OYVwAAg5fYNQjK89CqK4sRnvRQru8dE1dOX3S3BNZNC6\n8Cw5BXYpCRKq4PHJrdmoygCjVC9K7pzE6MQ3dHBvSK9m0djzLwipDqmYH9wvckxZODywU5nC1Yrz\nBMkztM/0mOdynPN3AuMxmU5AGdPFiMk8UxeK50qfeAqFQqFQKBTTgL5MKRQKhUKhUEwDs0rzgZjy\nCGgASRfkBbVQDLSOIkwPPfbgw74d0DFSoXypo5XyIvi1N8N9BurXkqYbHGSl53jc9iljZ6Ukldft\nEZRZpo8pxUoXmC1pk4A+CovzqIoxvRRQihUxpgt9AVsAG259CwDgkXt+xnMSvI1X9ZG20vjgX7nO\nct9SGanqQLdooIsps2h1jW8HRaorapl2razj7XXNLmhfBC6HRdB8wDtViNVdtHoFz9UVkm5eyNem\nmBsf5PylL3/F24bTlgaU2k8jKaYGs8PuOkT5ls8Xxyt7Q1By0QRfk1w+iNbm+ymf5+sUqOOPovnK\nXgcZgB4aZyuWURuXc8qmBIVc7trJsaJ2nUJFoSsm+3eVqItC9T3kVOklNVkuaL4kdM3k/IIJGIyf\n20WP5FxPYJpIuj/JKe12Vn0rBM5koSfZVTH3UM+UQqFQKBQKxTSgL1MKhUKhUCgU08Ds0nxgiiko\n3zEqe0lQEOXe8yjE1EEul3X98DH799kCwDJzbhSN6AoAj4wwNRgTxXqDMjSN81kH6sQR1jIKKBSZ\nDRcLM32XdtltUncnKB8iS37I7fmsm1NGFHwWhYpTqdS4MUfL/phxfZYDja75MW57qMz2fJGz9UZS\nrDOVqLI0ZXwCyqzklj8sMrqKck3ccUVBDxXFtaWIpaciQu8rLLWW3HX69P/9rLd96uOfsucR5f1i\neb62gwW7fkGGnD3N8Vl0eVmIuMjnHBRnRkRk1kXFvZsL+vQmplNHLbf8D3J9h4VFZl0GlDgfk4jw\nOeVKfJ/43sX5xciuc47EfqL8UbDkozTKiuOz8Yy4N4xbp5rmRm8b7jnF8/f7XuTlZBRzho0bk769\naVNywv0Uc4uZysK7UIojq2dKoVAoFAqFYhqYVc+UMWaULhQAGKGAbkpS8ynQ6BEaNqLwbkWF9Y6M\npKS6syvcOoGXJh/YhYSOdCVk0vbdcmSEA5+vvXkDb3f2dI47OLBzt28HStLhCC9r4P2QquNF4Z0o\nOC9USahkw/DxQ4OD4+Yp+xqlwj1mTNmWQeflNKfCQnU97DwhRgQmH9m9y7e3Pm1V29deutbb6oWq\ne8Z5d2JCx0lek0DhPC+K7n7ps3/u21WViXHzjMZ5TT7xx0kAwAff9l4+ptnqdI0McNB5Is56XsHx\nEaGJFHj9AC56HBNOGrk94pIG0hnuP1zFxamRd4kIIlg7UH0Pl7lGAGDKeW9k0L5LshC3PYoyGNx5\nmaQn0wjPU955ekdpQmGU6wzAmPvJXZvRhYzl78mNL+6XkBjTa7W9HAPQFRcUksLNkZyuy+NMjj+b\nsZJj/p6nONeeo/PZSzVlzxQRhYnoBSK61/13IxE9QET73N+GyfpQKBSKuYA+vxQKxbnEmdB8Hwew\nS/z3pwE8ZIxZDeAh998KhUJxPkKfXwqF4pyBymnVjNuJaDGAbwH4cwC/Z4y5g4j2ANhojOkgohYA\nm4wxa0/XTywWNQvmNwFgSq7LlWABgJpapg7SKVeAN8Lve1VVssirpRYGBoe9qVRG12fMebg+x9Nw\nAJdUkYWOJYIg7SVLlnhbVMzpgAuAL+R5zqm0pX9Mnue2rK3Nt+OV9vju7m5vk0H1i1csAwDse5FL\nyJSK4wOPJcpdU3nOZcvJiKULChTLfmJCJ+rzd30RANDcyuVacoLGC2i+qKQWBX/12P2PAABe3LbF\n2zr3H+e+3GRSKb62TfNEwLMr3BuL1XtboIWUETQyk4xA0d1aOVECp7+X772wsXOWayMLSmfdmIk4\n3xslw+dccAkEoylm25cZlWQh1p7G03ySjpXXjCH6oqBcjDhGBLMXHc1IpnxCBhdSZpov7BIyJJ2Y\nEEkaQcHraJTXRlL3/jdWwdt7Ojq2GGNeUeZkZgUz9fxqJTIfPd0OyZma8dziQtSZ2igG2DTlwaa6\n35ijyizQ2fU0g5ilCWycZKCN5xv3NgZBwoJMYpgCpvT8mqpn6ssAPglAvq0sMMZ0uPZJAAvOZHYK\nhUIxS9Dnl0KhOKeY9GWKiO4A0GWM2TLRPsZ+7pZ1cRHRR4hoMxFtnsxzpFAoFDOJmXx+pcrtoFAo\nFJhaNt/NAN5KRLfDMie1RPRtAJ1E1CLc5F3lDjbG3AXgLgCIx2Mm0LThMiY8hWxmfBaaxKgyLllL\nLcgXtEkpS3d8Lp8XJkm1OKpIlKiJiqwlOPrr6LEj3jQosseC0SuqOcsrYGCK4qM4l+P+KWbPf0iU\npTGG51fMLXRGke03iWaUXIeAAipNQNkF9JXMMAwZd43E2so1+dT//H0AwBe++ffeFk+w3lbClYn5\n+d33edumH3M5nLwr8UOiJElaZKSV3JrLJLjeAab8Ik5rKZ1jHahYpc3cq6kSFK14d88M2+tkSkxJ\nNS2Yz/0fsdc0KigtyDIrjnLL5EWGn5hgwa1faZSOk6O8wpKaK6OfJq5nWGQb+mNGfYSI60RB6ReR\nTSf1yNyuJiSvLfeUdxmkJDjeUCHI/uT9sllxbYISOKFRaYd8vPt9kzlvPpxm7PnVKgW/FHOGckzS\nmchNBcdPSmeKHSS9VY7q2iTak1Fh5wLBVDfJOY/KVpyZcWSfZ0mZXbSY1DNljPmMMWaxMaYNwK8C\neNgY8wEA9wC40+12J4C7z9ksFQqF4iygzy+FQjEbmI7O1F8B+D4RfQhAO4D3TOUgH3Tr/o4uqCq1\nbexf+VEuv8CpXPCuL8I6vjCrG8D+EdulvlKIXGFY4XHI52Wwt12uQkEWuGUE3coxi0VfitjbAqV1\ngL0HFcKzkxMB7M5RgLwYMyqUx4NepVbQaE+HPadwRJZsljpTbswF3Ge813ckDuH2q153E4DRN09J\neC/+7LNfsLYC27Ii8JvMeOVvIwoIlypszyEZbF3g+yTiPGskkhPSQwMAgKEs9xOPc3KAcR7ARAV7\nDfNZMSc3F6khVtfAAe6Vlfa4YoaPyWXZW5Z3nju5yoGOlNSTCol2EGw+SrEf0stj2xGhtJ7LSpG0\noFCyMJE83ulQCa+m1H+KBL83sY6B3ll1Ta23SSX7gZ4h16fwdsk5B22SK3Fe4qyeX4rZRVkvlHBD\nlfOKTNcLE3Q/Fx6mc4XJvXBT209CPVKjcUYvU8aYTXAeTWNMD4DXzvyUFAqFYuahzy+FQnGuoOVk\nFAqFQqFQKKaBWS8nE9BR5cqgyELH5GmC8kHQwXbJcPhSFhMEoofK0CqyAG/YUUHhsCxrIwsUu+LM\ngvKKyAB111dJ6ERFHEVSpPJBxMbZ0+Lc5PhFRzvJkh1FoTMViVh6UAbKS62jgEoKSpsAQCQuqE1H\nIdWnOHCbKuycqqqrvK2vi3WwQrDHP/fEL73tkZ8/zucUqbFzygtKzNFwABBJ2GDxvCxuLOjeVZff\nAAAY7ueg/KoqnkvncVvCZ7ibtwfXROojVdXW+HbK6UClBnkepQLPL7jO869cxXNu7/Xt/q6T9hgR\nwB4J85oFjNmo0i0BlS2u9yhy2m2X5YcK4joZ1y6WimMPce3x93lRaF+FHeko4sNRNOPp8ZKgkINj\nRgW1x8S95/oKybI2su3K0RQ1c1chMJPyQ+XopbPRN5qohMzFRO9NFee5PNQFAfVMKRQKhUKhUEwD\n+jKlUCgUCoVCMQ3MKs0HMM1R8tlnkg4QWUGOngpLOlCWfnEaRRFBiQXUxOiSHoxyoqGS8isUSu5v\n2ttGl/QIym+MPx+7wW0XdGXQf2FUGRBuR52uUDzONFYuJ+QBS8EIIuNLnEbM0XvynGMxzgwM7KMy\nIaWukFvHkhizpslmyxVLLL0jKaVHHnwUALBkZZu39WZ5e2XYjjkywJlnxZBYR3ftZYmZSAUXf0k4\nqirWyBllRqxZhOw5R6vFdpexVhtnaq8U53XID9nzy+eZ0oonWG8rWOaB3VzWpvz9wn2iJKhZBLSz\noHDd8ZJZkxmIsVjcHcMoyuzRUJDxKrIzxc7Bb0hul19HBbeOsv9IVM5/POVOjnodGhgUR4l1cDd/\nqChKMgkeMe/4zkgZOlGhAICNG8fbNm2awQGSZTpLlhn0HCEoZyPL2pTXpmLb+K1nh/O9nMvFDPVM\nKRQKhUKhUEwDs+qZKpUMRlKZUbZKEVicTrNHKCg6HI2y56kgPCpFp0uUFcrZQeC2KVPIV0KqOwda\nPHJM6Y0qiGBv4/WRuIPwKMeZPT6TYS9PPGE9LiS+7gslMedCECDOgc0yytgH5UutIOGaGkml3CHC\ny1OmkLMMjB4eYeXwYM1iYh1iTvOqbXGzt23b2uPbC5ettHOLsWaTyRzy7aBQcW/vSW+riFeK/qvc\n3LnQcF541g7ttkWdMwX2bEm9rwrnkaIU3y+1TlMq1dvpbZkE60wFl6xOKJxnUux9Ibe8oQR7yEJC\nNargEgFkcgCKIkjbXR+5zqXgOgmvXERGkAeeIaEBVtfY4NtD/XZ9pHc2luB1zIxYzSeZXCD9QUE7\nIj10Iuje3ydF4fH1CSLSkyjnbM+pFBEFoWO8zkHRY3P+KKArLjJMpjM1GSbzEs0UJi0KPMozNfPj\nzwWk13FGvY3nEDM1Z/VMKRQKhUKhUEwD+jKlUCgUCoVCMQ3MKs0XChESjkYJaBtJ7Y2qHePolKKg\n9kbrRwVFZMuUrRhFk42n/IwosFsaFTAc9CyCncMyQN1SUaFR/Y8vKjyKZnPjk+AWEzGmkoKxAnoE\n/6+9M4u15LrO87+qznCnbjabEpstShZFhJAgSBDlEIYd86Fj0kYcCJaf6BgwQjgOlACBhyCGIwWB\n0X4w4AfDiB8MA4ISQ0I8SFEiiNCDEotxA+aLbMoyEEUio4gixaa72U32fIdzTlUtP9Tetf/dtc+d\nznDvOb0+gOi6Ne69q26x7vrX/hfifnr/KPbtOUhqr2/TiOTQjNri279N5V62vld7Sl3+fpDhhJLa\n1clLm8PQppMng+T32vdqH6h+h45BOH/pE/1JusvWgnx108lvJ0490Kwb3Aj+UMW2kzZJAr5zrZYh\nh2T7tXU9yK1eKdumEjf9XkhWz3vqzh2ex8hvzCeTg6U9tJajR9RdtEvFi6NSQy4ZviSfp1JZWhz5\nhjTrhlx2p0xMiKA/j5oJGcO0DMi+bs26Zlu4t71uuDeCWiLuUEmj4Q6XuKmi8xiLwyxzl1NJ58Dx\nkYKOo7fUkx94pVl+4aVHW9vPT/Fa+z3XpBLrcWHc8zgJFpkyDMMwDMOYAPuYMgzDMAzDmIC5z+bj\nkjDA3T5OgVQBDpa/vFrCskkKLrPiS6vkKWkQ5AnFJWZo395aPWtpjSSpnNp3w5U/GQ6C7HHmoQdd\n28N+m7fCLLJ+v/YaOnEyeCZtD8IY+XI0J2n7bTp+bbVu0yq1aTgMx/vZWSwj8jf0+np9/IDaPHRS\n2Po6zcAjH6yLP3i1PjfJV6sk6W2s1mVWtmjW4GAQru/P1V0nnyeaOddxXky33g4yY94L2yvveTUi\niRV+Nl3o26l3vLNZ3rp+FQDAwlYpNEPSS20k61b0aGXwpWHoeBKz/GPIz6ivlsPlVnLhmaJtmY2f\np6773eCZnlXFEu3QXZtbxZ5RTtaO5EiSkH2faLZg5raXPAu2G6TRh87WMzkvXQyzNzUqA+VK5Iz5\nHTPmzPmZ7Hpgzl0IyxfOHfya+90vPujcnruk8DP7jqP0d9QssrQ3aywyZRiGYRiGMQFzL3TMDtRA\nnHMee0J592hy7ubkXeeNk4pM8XmiBHSf7E3+RamiyHwMb/dRtGInfXzlok+UM49rLrrCkamH3v1w\n6Idr6uaV4DbO+w7d+bc22x5cQIi8cTSsKNiTyjnFU+SopOjHoKi3r548FRp96w6AOBrVIc+mU6t1\nxEo4sboXxvzKaxfdhcjNm645HNR9yclFW9ZDAnuW1wO4AUq2Jm+uHTdoq/3gyfTgg/Xy5bep+DFF\nmTSvo2B5FtrM91m8e31kqcRRJp/sTW7kFE2rOhLtB4RnM5rwsEdm9s42eYC557W7FiYsjCjCl5N3\n193XBIDKu5Xz80wO7D6xXchnqnLLeUaRQgkRxCt/d9GfnE4TxlTd75bIXF8tx4PzR90AYxznDxBR\n8RGpeSbHN9dcoIfIJ6OPi1al186Ho7i2RaYMwzAMwzAmwD6mDMMwDMMwJmC+sXiRJtnVSyydbjpR\n1ScSV3v4K7FI5/dlHyhE0iDLTm388VESMZeOcbJIqgAut2ZlJUhqvi2RT5S05aMuFd0tScrp5vUt\nyiihN+ekfXf+ipPzu+3rd1fDMVy+xPc1o9Htn6glvWEZ2pFV1D43JFRRBDIIx9//YF2G5srfvd6s\nO3nf6WbZe4PtUIJ6uRmSzQuXTM5yZBXd/Hr75iBIo1dRe0bxOI5GQSZcdVLZ9jCsW1/ZCO134zAc\nhGRqjQprD92/1Gl+DJp9+dlx45xxSSSSucXvRwngJKmp1s9rOeCSRizhutNE0h7aRM8bFdn2HmZl\nmLCgXSfz0TM2Ilm8cM9EVLam4j65kk6JMk6GsR++Rv5Knidp+T/+a1r/gX/e2vcF/ADAwaS9vZh5\nceY9SPXlPHk+eU8q9qNqH3HvcH6P7XzvpuU5ta+PKRF5FcBt1P8XK1T1CRE5DeDzAB4B8CqAZ1T1\n+rhzGIZhHAX2/jIMY9Yc5M/Hf6yqj6vqE+7nTwJ4XlUfA/C8+9kwDOM4Yu8vwzBmxiQy38cBnHPL\nnwVwAcC/3/UI1WaGlJdAuJQGyxWSOb+abIxfTbNroqYHWNojjx8nPYyzpmpmXyVm+AFB3hvnoeNP\nW9CMxV6vHmKNpi3S8d6XJ6PZduR/5MvdrNGMrls3guyS9WpZqMfSHp1fJbEuoVJmOc22u1Off30t\neFup8KxIN5OSPI/8/QKCqnT6wbO0jvZ1fR4M3mqtY2IVjcr+NA0JxxTb9TivnAzjwLPt8tV6nPrr\nQdqLfMtc+zq9cNWdnVCORgf1PclohmCn3x7zWAL20mGQ0fjZyd2vn9LY8/PuSy5VdMM6QvcRbSqS\n3Pw94VJGfJCXD0ekDXa79TiVI/695FmP7t5zqR2evtr8DsWzdo8hB39/GVMnJekdF2ZRcmSaxNLf\n5wAATz90PrVrOOZCevuTifuQKmHDLLLnFN/bacm1+41MKYCvicg3ROQTbt0ZVb3kli8DOJM6UEQ+\nISIvisiL4z5SDMMwZshU3l9bqR0MwzAAyH4+cETkYVV9Q0QeBPDnAH4ZwHOqeor2ua6q9489CYA8\nz3VtfT1ax8nikT+Ua9e4ZG8fyUh5QmVjQk97RZ5S63ldv9+NzgMAyt+jLoLAPlAdHzGi87DPVOV8\nf+5cC67mW1vhtf3we94FALj25tVmHY9Td62OtBRUyJi9kgof1WB/L4ro+P55J3YAuH27LmTMTu+c\noO79tNi9vqLois+CjiKN2va+euvSpWbdiCIqvn+c2Bx5jLnwCkeeVp0TfEH7cft9ZC/LyIGcW4fV\njgAAHb1JREFUErO18P9SOznalvuoZtr3bOSKN/foeRiUtZ/W7WvB+4rHft39LghNCODJAXnlkrk5\nER50H72vGd37gpLJ/T0vlCc/pH43yI8rsZkd3P3vm4AqSktI2vfVA/jZuPHW1W+QvDZ3pvX+epeI\n/qsZt3VZmVUE6umHPjeT8+6HWSSgc8Tka5fbyfXjmNc4HKRNh+HpPaJhk3JuD2+sMezr/bWvyJSq\nvuH+vQLgSwB+BMCbInIWANy/V8afwTAM42iw95dhGLNmz48pEVkXkRN+GcBPAfgWgOcAPOt2exbA\nl2fVSMMwjMNg7y/DMObBfhLQzwD4kpMHOgD+RFW/KiJ/DeALIvJLAF4D8Mx+LuhVhJRMx/JYSo6I\nEoa91MXlXhKJ4VHisrblp7h4crtNkYdP5dfxFdoyZJeSwfOO98siKYVLjvgul5TQW7DkVd8i6YVz\nCkluvrwIS3+c7N51ycdlxv0k6XKllr9KKimyurLuzhP6xOnEvv+VkicTtR+5l2hpoEac2F1LUTz2\n61Suxh8mURkWmkjgjjtJJXC2h7WktkEFoblo8OZ2LYVt3QoBCC8NAkDPFXyOfM+ie1+PwIhqEwv7\nkTl5riQ5s+9K2PQfCrJuJNm5xG7hEjXUz+2qngiwdTNIwPzorbpC1L3VMDlhlXyqvBzKNlAsMzaS\nHanb/p4WdL8q6nThvLvyDv+OtItUH6P8yKm+v+5VWKabtRSzF0cp7Y1j0mT1lGS4Vz9Zctuv/Dbp\n2E16/F7tnJYcfBTP6J4fU6r6CoCPJNa/DeCpWTTKMAxjGtj7yzCMeWA2xYZhGIZhGBMw99Luusss\nvXiWXHsdU4VaGq1jWGLg62SHmM03rn3NOVlec8ezl5D3+GHprUO+P1mnlu/6/eAdpVmYhfbWpTfr\nBfI3KhJDUhTptvsZYzu3wiyvbCXMxKqcgDdkvy93qpI+tYVmzmVOKirLIP+UXLLEdZVlQu+ZBACV\n26HXC/JUPPR1W5RELS6no+4+jEh87Dm5MnquuBRQpz5m/f4HQjto363b9QzK4TCM02o/tO++++ty\nOB1pP7cAUPkyKmA5tb7+DpW1yWk2ofeBykjm4xmEK076XF0LM2CV7rMvj9QjCbgZfACD23W5nu3b\n2+H6tOuJ++qx4Oe1me1I7eAxuf72tbptG2Fs7rx9u1m+74F6QpySRHvzbcvtXiSOo/fTMkp7k57r\nIDLgbusOcs5JOcz5DzODcNwzfM75cbGvVuehIAkWlw/ut+WxyJRhGIZhGMYE7Mtnalrkea4rlPS7\nK/6vdc6OjUxw/F/gUfik3m1MAnmWpaNczekTCeoc+fIJ7uO8hvxf9Tyi/hjvvwMAXRrzVXfM1mqI\nFt25fjO0yfVl43RItga5ifvIWMmeTBQS6jqX7hVOYKfI2A1XbFioBnTXubZzNCnLyVPKJy6Tt1Qn\ncmB3Sfec3E9RpvDMpSOIkrhP/Jimtvv7wJu4qLC/9+NqVHsfrYojS7S9GNaJ/jubIcrTXw193jh5\nn7s+9Ul9MjZdlPLb1f9AifpV4j4KRSWjKJI7nt3puX/e62mHIks8+SFXX2ycPKPc75X3GgOA0TYV\nvHb3ttsNz0OnH5bVPc85RQVff/nbR+ozNS0W3WfqKJN7D3vt4xiRWmSm6RN1HO/NLHywXnjp0en5\nTBmGYRiGYRhp7GPKMAzDMAxjAuaegJ7yckrvV/8by5Cpci8k5TTy1ZgEcyfc9EjWiOQ3t75KeE8l\nGweg0w2+Pl6t6dDlC3dNlsxAXkZbo1o2ysqQpNztsm9PLYvGRXlDn9dcEvegCFKM5KF/uV+mz+bb\nd0K5Gm8/JV2S4ZxUVZGHluR0fSfvcfI9L5dePuLE6g5JWWXb3yhCfTvCKi4wvCvKsitNBGjmK+x+\nbyl/O9qeO5n0RC/cb27f1rZL9r51p1nX6dVjv7YRvK9WuJyN83SKrsNle1zzMwnHcOHuEu3jT54M\nhZzvuLJEKx163ivuf31elkM7bkLE+saJZt2wF54tdQ9Mh9rEpYZ8KaTNrU0Ys+E4JoiP4zBtPY7y\n0bJwmKT1Sfed5/2c1rUOIxdaZMowDMMwDGMC7GPKMAzDMAxjAuY+m291zXkoNdcN33OpWXQZrYuk\nMre+S5LdOE8qj58ZN242XtXoNmkJkqWs5pxcHsTJJan9KpJS2Bco7ySU1oSkxe1cWws+VFu3a1mJ\nK7dsbITt4qSure0gI0beW66t7COVmtWY8tOSDsloWXtmHstTqWuOe/ZSEjBff7f7HE/4TJw/53ZS\n+90sunHn9utVxvz9EdVscW1x/RsMwtgPaTZgt1efc3UlSGrdteDf5GfuaRme+4Kly8rJfDxFkLc7\nSXN9PciMO0Py+3IleNhjLPPlj6ifOY2j9/jiaYO+hAwQfgdKurdvLMlsPpGxwvSheXKBJDsPz+ab\n2gxBk/YWglnMlmOO43Nw/sJ5m81nGIZhGIYxa+aagC5ZhpX1OkG2iV4oe+S0l4WSZ/u9sOz/6k9F\nTMZe3/0Fn2Nc9MH/Sy7ViaLIvK5DkSW/PWqH8zeSghOHOZm7blNGUR7lJGM3Pv2VkPjMEbqO85Hi\nItGDUViuKpc8XKX7HMaPImzajgwpO5zn3kcqJO9L4vxRhCnn6IZbX46JMHmzqDGFjr3vkqQiiFRQ\nmk2nmntHHl18vI9oVVFwlO4zfNJ92D6iyQupY/wD1adCxD26jz46O6LJA7evBI+x3Hl7rawHb7YO\nRTWzTt/1ifqRkU+VG4vN2+GcVWJyBvuFqYt2KRW+LhO/A52MXPRTkcR78O+0RYwyHYZJo1HHMfpg\n7I9pJrBPevxxe47uvTeeYRiGYRjGFLGPKcMwDMMwjAmYr8+UalOWo5GXKNG1k0rGHiPJeVlKE5uz\nZOkSkD8USzHtxVQCOUDSI8ke7FPlfY2iS3rdiJLKuxn7BpXuPEEq6VGpjl5TKDmcczSiayY6UkYy\nX31gTuPMso6XHDNSrHJ3fZYOc05Qd/Ib1/zNKAm5GScaRiX9zN+zjCWnSBl1hZTZQyyLTuYOaSel\nx/nhdHP9TRkjBfs9lZOxqXRL5SRDlmAjCTiR7N5sFZai22VzcvIqWz8VlsUNcLETEtg375CPlfMQ\niyY00HJTJkbTbfZyrZCkVyWLdYdlL23uVEGa7FDufeXHYfe5IAvJxsqH8Pgjzx11MxaS4ybJGLNh\n1jLgYc41r2fPIlOGYRiGYRgTYB9ThmEYhmEYE7AvmU9ETgH4DIAPoRZk/gWAlwF8HsAjAF4F8Iyq\nXt/jPOh1e83y3aRm41U8i4yknspJWVydvpFiUv5CQDS7i9vUbHbHjTs87Moz06itXv5KzQAkSawA\nzbhyM8pWVsKMr9EgaG75Si3VjKgETGQr5CSkIclPGZeTcdvztbBuRLKRuONKLv0yrLfzeBc048xL\nQMKz5Sruk1tXhn5oTjMk3R7jyvaEmZqhoyynqhu/eCYl3DlpBh7fnK6XYOneJZ636HmgGZYseTZw\naZa7/o1PStfkGYhl+5px+5wM2AvPxgbNDPSSJM/uHFxvl3HJ1oJ02O+TjFjU51/pBmmw62YADumB\nFXreV9yQDIv0OIlrU0p+Pyqm9f4yDo7JewYzTxlwv+ec1jO638jU7wP4qqp+AMBHAHwHwCcBPK+q\njwF43v1sGIZx3LD3l2EYM2VPB3QRuQ/A3wJ4VGlnEXkZwDlVvSQiZwFcUNX373aubrenpx94B4C0\nZxO3JXdJ2tWYSEKTv84O5okE8Zhs12t6g2PV9HYfqSkooZeMv6G7RL54P/bl6VGkoYGiTD7qEHlw\nUQJ530UVODrB12oKS1OUJxV6Y/8hfwxHfiqqAOyHp1OlvbGacco4crN7VJDxh/E1M/KPGknh9uMk\naRfFydtO7rzMTu1JKNmaqYq2uz2fqhxTXBuIC1MrjVnF4crEORvX9TERPH/N1O8Arx9sBdd17yPF\ndDvhGez2XbHvnBzOM0pqd90v6c+wnCdHVO1xev3/vXxkDujTfH+dWP2wWgL63lg0ypgVs3ZgT/HC\nS49OzQH9fQCuAvgjEfmmiHxGRNYBnFHVS26fywDOpA4WkU+IyIsi8mLK3M8wDGOGTO39NSquzanJ\nhmEsGvv5mOoA+GEAf6iqHwWwibtC4u4vvuSf5qr6aVV9QlWfGGc5YBiGMSOm9v7qdk7PvLGGYSwm\n+0lAvwjgoqp+3f38RdQvozdF5CyFya/s54Lebsi/uVjpid5mvqwFJzlz4rcv78GSnd93jHzkg/w5\nyS7JKitRwnB7WaPyHe1yMvE1XbI0lxGhi+64YrORnMgZ5r5LlOSb05gMRsPW8VVUyNm1o6Ii0URy\nIoDzH2LpKmNp0PsjdagdLHk5GU6HdHwv9SGdLjjtLbfY+6qMNDVfdLg93gUXHCYZzY/pznZIpGd/\npqDsUiJ9Ymw4EZ1T0sWNj5LfVrgnfB46v7ul3I0qlRRP97skTygvw6akPaZH5WiUh8eVnhlshgkJ\nA1eImc/JhbVLJ6Oy1M1J7V5mLRKldo6Iqb6/jBiT9Ix5chQJ7Ptlz1CRql4G8LqI+HyCpwB8G8Bz\nAJ51654F8OWZtNAwDOOQ2PvLMIx5sF8H9F8G8Mci0gPwCoBfRP0h9gUR+SUArwF4Zj8n8gGGxETz\n2Prgrv2B+K/uJqGZt7t1MsYBvbm2psNhlbvquIRfH2FgR2hEkRBpHdN109o54JCTdUGxU/8Fn1OC\neJQM7sYkIwf1kpO9tf09rBwJaSIZ3Cd2E/eO1YkozJCiWZFEW1+/cyJEPPrrIXpx6+qNejs5uXNu\nfjFyRa4pkT7OT3cWFVHYUlvbIzdy1z6lvlUjStp34Z9ujx55tt3wifoU+dHoPiRCmPzseesFblP7\niHicy9ZponujLjrE0dmMlhu3caS3D121AW57Rs+ud67osV0C2oWzy0F4DnZGW65NZJsxDH32z3G2\nV6L/fJna+8uwaJRxfDnKyNW+PqZU9W8BpLLZn5pucwzDMKaLvb8Mw5g1lhFuGIZhGIYxAfMtdIwg\nSOTeBZu2cdKr384FgtPO4m0voUgQInmo9N1NJC4DQSLhNkVJ5S57d5xLti9qHPkzuUTdguSfyOep\n4+UpOmdCZhxFkhvJnb7N0diRVOSTnMHyEPkeNQWAw+m76ryGSKqpEsLsza3bzXJvmxLkV9uPVTlq\n36cy4bNUb/dyaXJzUyCZLJuaZHShu9fptpPBNboNJJf6+xjJaHSuxNwGfjYKV3w65XOlY5LaffFn\nPg/lr6NwzxsXmY5c49F2dWe6rtBx5FFG9z73Ew1S7u7UD5Z4ffFnnnww2toJy/5aY/y6jMXCJD1j\nmZilDGiRKcMwDMMwjAmwjynDMAzDMIwJmLvM58P/Qe4LaKKkiY6bXeVkHfbd8bOeWPrj2VEZfFHf\nMcWT3XFRm3i2nztXRf5J3RWSId31RyyjuTIkLB/F0qE/OKwqy/BDLq48Bx/Cqo6TikTbMyHrDQkp\njXyuOq4AMc8g1MI3mSSrhOTWp3IuBUlFnbxdtqesgr9T0/+C2sazEt0sv5LkKfa58ktcVsfPWmQZ\njme25b7QsrD/EXuE+WeH7h3tqQlDMqVT+ccskpWdjMjPMLfJy7mRVxoNSQf+3qRnNbJM6clp32Lg\nx5yeDXoemraW7XWRlM0WY+5cVUG/A1SIuTmejrnTaqVxnDFpz7hXST37L7y0v2MtMmUYhmEYhjEB\nc49M6V1J3PwHP0eeUkWLoyRr59VUUhwmc3+Vszsz+zd5xvlQNdEuTUfDen03XGRmXg6Ce3TWr32X\nKvpLv1RflJd8oopwfX9O7luqJnGUYhxF1rS1jnPd/fBFOfc5u6W3k48rFxmTnKN2IQzjo3l877iA\ncDHcaW3nr3YfwWO/ryiK5CM5HTbnCt5cVVEn43coMuWfg9hRP/Rt5KI0vW6IohRZalLAGPf8RAI+\nF2JOJoNX7SgP459TTRSeBsKYSpk+3t8HPv9wGO6Tj1zlNE7cZewyYSNV4BuIn9Pd1pWjY+OAbuyC\nRaGMe5ELF2gZ56dyTotMGYZhGIZhTIB9TBmGYRiGYUzA3GU+XyLEywhRYnEkF7hCxmN8pjydqAhs\nLS2wzxPLFb7UR5a1vYCAIOlldDxLHLnTrW7evNmsO3nyRLM8ctJGWQZPKJ8APxoFmWhlZYWOGUb7\nAUGuBIJUE5XSSfhtsVTDpTyCpMlJzjTOfvwidcqNE6tsWftR4dIrZUJazaJE+3ZZnowTqLl8ifjt\nXFqFx9RJxJTA7qUyLlHDlX789UejcB7vwwQAIy8/R35cJON51YqeR0TdS8hj8HIm7Ud9FrfcIU+n\ngq7ZlXrMd6jvGY2juH0rnnARLhXmPNBAlFXb84qT633/t7e3m3XcPj9+/IwqT3lo1NJjVU7GIEza\nM5aJWUh2h8EiU4ZhGIZhGBNgH1OGYRiGYRgTMGeZTxtpwnvrRBOVSEJptpOEEc3mc+uVJ+s5XaMo\ngpTBMp04CYhlCeHSLE5qY5+q4SCUyqjcaK2dCNLeDslTvsxJLEfWy2sbYQrgcMhSS/t7liWzlLRZ\npWS6MTTSJc+8Y08nd6oSYfZV7kqrsM9URdJl005qe0d4tqLzxqKx50uGGYY8my/s0MzGZBmP6qx4\nBYllPi/tlnTvo7I93gOMfKaE2+ftwPgZJH3OHxVJlywJlu1SQyW8bxlL0fzsuVJCA/Lo6oVfyaE7\nZ4b0bLqu63MRGV7xDEN3ngHN8CvasxK5nIyftRjdDypl5CXiSEGl64f+7/5cGvPH5D3juHNcJLvD\nYJEpwzAMwzCMCZhzZErgv9/KJhm8XYyWl9kdmj2j/F/T7MHjk5DzjCMv7KlUX7ObhcTjTNrX3xls\nNeu6K6vh+m5fjn70yLNp0LhCh7/U+506IlVsUzQqUZiWowNRNOquhH0AEC6uXEjrGM3b48jBLGHn\n8Mb1nZLum4Mp6ibtR6VHifqjIvht5VKPr3IGeJTo787J3lEVJ263ydkSyp2h0+nR8SN3GXJ3pwRz\nddn0/Swk/4MmBfgca3YbF+pfL/N+YOHepu4ZR7O8QztHk3q90ObCPScVFWTOach4IkXTD+qfusjc\nYDu4y7ODe1HU52cPME14QnFxaL+9iis6t4+RdkR33HZjvlgEypgm5y+cP+omLAQWmTIMwzAMw5gA\n+5gyDMMwDMOYgD1lPhF5P4DP06pHAfwmgM+59Y8AeBXAM6p6fbdzKTQqAgwAZdVObK5xyeC0puJi\nut4eKUrWdvuRFMNSiTh5T8ggiD2hhq4MSm91g84ZWrDjtq+uhmTyra2d1r59uuZwWEswXFqFk7V9\nsjVLb1zAtinAy7LJOEnQEfkzeR8q9p5iFdEPJMulvsxJW22MGIyCvBQlSfsSOh2eHdCeFMASK9+z\nRl4rOcGcJDsvi5H61Ou4Uj48dlSyOl/rufME2XZtbb1ZXl2tl7MeScDdcJ/D8EWZ/OFa7jm+dvXN\nsN15Mg23QqnfgsqsSKIQckG/D1s3gp9ZOIiSzcu2ZFckJgrw740k/n4S0dYy/16xTJkqhMxoQhI8\nSqb5/jLuDVKy1vlz7XXTPL+x+OwZmVLVl1X1cVV9HMA/BLAF4EsAPgngeVV9DMDz7mfDMIxjg72/\nDMOYBweV+Z4C8D1VfQ3AxwF81q3/LICfnWbDDMMwpoy9vwzDmAkHnc33zwD8qVs+o6qX3PJlAGf2\nc4JGYmvKTrS9pYAgM0TeUtL228mo1IWXeHgWVzRbz51+sB2kOZYlvLzHs+2GwzBLzfv67GzRzDX6\nHu2560azvHxpFZZKSCrykpzy7Ci0pcs8T896rPapqrCnEws0Wrr2sSKXkFhTZVZYQt25fYd3BgB0\nu0EuXdu4L1zTL1CfTj/wYLN85r3/AABQSJDZAJLcXGP7vbVmXdMWnoTGbXYz22Lpsl2ih+XYjGS0\nkbtPeUHSHkuzboZn7+Rj4ZxlLYN28yDNvfKtbzbLb77y3fo6FT2PXJqlchLx2JJL9frIJyrhURZL\nbyQT7kJcsojkdTfOXZJDT54K9+GdZ99VH98Nsxb/5i//al/XnAMTv7+OGzZzbzocRHozmc5Ise/I\nlIj0APwMgP929zat39bJ/62LyCdE5EUReTE1LdswDGPWTOP9NSquzbiVhmEsKgeJTP00gL9RVZ9h\n+6aInFXVSyJyFsCV1EGq+mkAnwaATrer3pE7BA24WG50XPtcnPDrPwPpL3Hve1SxGzdHmbZq/6is\nG7rdIa+jkYsk5BU5e7MTtEueVzp/lyI6g0EdsWLvLO+CzV+tnGztozNZVLCZE4Kdq3tJDuWUWC3O\nGTynCF0qXCVUqDjyrMr9ecI4NNcswjW5KHHWr6/53sc+3KxbOfFQuNhKncy9thYiFt1e29+JE7x3\nyGm+362TxDlaN6I+dVxbONXa1y/uUmSHneT9mBQ0AYKjnlVTNJiKAhdtZ/AbV283606/8/5m+ebl\nq3U7aELC5R98HwBwZ3ijWSeb322W+TlprqPtxO7ofiWKXO/l6dShiQC9XrjmqVOnAAArp4KjP6S+\nZzxNZDTiZ89VJqDfW5+8DwDXNut9u9J2Wj9iJn5/nVj98LHIrrdo1P6YZgTJolHGXhwkZ+rnEULk\nAPAcgGfd8rMAvjytRhmGYUwZe38ZhjEz9vUxJSLrAH4SwP+g1b8D4CdF5LsAnnY/G4ZhHCvs/WUY\nxqyRefrCiMhVAJsA3prbRefDO2B9WgSsT0fDe1X1nUfdiElx76/XsBhjfhCWrT+A9WlRWIQ+7ev9\nNdePKQAQkRdV9Ym5XnTGWJ8WA+uTMQ2WbcyXrT+A9WlRWKY+WTkZwzAMwzCMCbCPKcMwDMMwjAk4\nio+pTx/BNWeN9WkxsD4Z02DZxnzZ+gNYnxaFpenT3HOmDMMwDMMwlgmT+QzDMAzDMCZgrh9TIvJP\nRORlEfn/IrJwVdpF5D0i8hci8m0R+b8i8qtu/WkR+XMR+a779/69znXcEJFcRL4pIl9xPy90n0Tk\nlIh8UUReEpHviMiPLUGf/q177r4lIn8qIiuL3qdFYtHfX8DyvsOW7f0FLN87bNnfX3P7mBKRHMAf\noC7r8EEAPy8iH5zX9adEAeDfqeoHAfwogH/j+vBJAM+r6mMAnnc/Lxq/CuA79POi9+n3AXxVVT8A\n4COo+7awfRKRhwH8CoAnVPVDAHLUhXsXtk+LxJK8v4DlfYct2/sLWKJ32D3x/lLVufwH4McA/E/6\n+VMAPjWv68+oT19G7az8MoCzbt1ZAC8fddsO2I93o36QfwLAV9y6he0TgPsAfB8uJ5DWL3KfHgbw\nOoDTqGtqfgXATy1ynxbpv2V8f7l+LPw7bNneX67NS/UOuxfeX/OU+fxgei66dQuJiDwC4KMAvg7g\njKpecpsuAzhzRM06LP8JwG8AVCV4sfv0PgBXAfyRC/1/xpUUWdg+qeobAH4XwA8AXAJwU1X/Fxa4\nTwvGUr2/gKV6hy3b+wtYsnfYvfD+sgT0QyAiGwD+O4BfU9VbvE3rT+yFmSIpIh8DcEVVvzFun0Xr\nE+q/fH4YwB+q6kdRlzCKwseL1ieXS/Bx1C/ZdwFYF5Ff4H0WrU/G0bEs77AlfX8BS/YOuxfeX/P8\nmHoDwHvo53e7dQuFiHRRv4T+WFV94dQ3ReSs234WwJWjat8h+HEAPyMirwL4MwA/ISL/FYvdp4sA\nLqrq193PX0T9YlrkPj0N4PuqelVVR6iL9v4jLHafFomleH8BS/cOW8b3F7B877Clf3/N82PqrwE8\nJiLvE5Ee6uSz5+Z4/YkREQHwnwF8R1V/jzY9B+BZt/ws6jyEhUBVP6Wq71bVR1Dfk/+tqr+Axe7T\nZQCvi8j73aqnAHwbC9wn1OHxHxWRNfccPoU6IXWR+7RILPz7C1i+d9gyvr+ApXyHLf37a66mnSLy\nT1Hr2zmA/6Kqvz23i08BEXkSwF8C+D8I+vx/QJ1z8AUAP4S6qvwzqnrtSBo5ASJyDsCvq+rHROQB\nLHCfRORxAJ8B0APwCoBfRP3HwyL36bcA/BzqGVnfBPAvAWxggfu0SCz6+wtY7nfYMr2/gOV7hy37\n+8sc0A3DMAzDMCbAEtANwzAMwzAmwD6mDMMwDMMwJsA+pgzDMAzDMCbAPqYMwzAMwzAmwD6mDMMw\nDMMwJsA+pgzDMAzDMCbAPqYMwzAMwzAmwD6mDMMwDMMwJuDvAfuHpGuktj1sAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc13e14fac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_image_annot(X[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_inputs(batch_size):\n",
    "    inputs = tf.placeholder(tf.float32, [batch_size, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH ])\n",
    "    labels = tf.placeholder(tf.int64,[batch_size, IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "    return inputs, labels, is_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss(logits, labels):\n",
    "    ce = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n",
    "    loss = tf.reduce_mean(ce)\n",
    "    tf.summary.scalar('loss', loss)\n",
    "    return loss\n",
    "\n",
    "def compute_accuracy(logits, labels):\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 3), labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    return accuracy\n",
    "\n",
    "def training_op(loss, learning_rate):\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.1).minimize(loss, global_step=global_step)\n",
    "    return optimizer, global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arg_scope = inference_scope(is_training=True, batch_norm_decay=0.95)\n",
    "inputs, labels, is_training = get_inputs(batch_size=TRAIN_BATCH_SIZE)\n",
    "with slim.arg_scope(arg_scope):\n",
    "    logits, predicted_annotations = inference(inputs, class_inc_bg=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = compute_loss(logits, labels)\n",
    "optimizer, global_step = training_op(loss, 0.0001)\n",
    "accuracy = compute_accuracy(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_segnet(inputs, labels, is_training, batch_size,learning_rate, batch_norm_decay=0.95):\n",
    "    class SegnetModel():\n",
    "        pass\n",
    "    segnet_model = SegnetModel()\n",
    "    arg_scope = inference_scope(is_training=is_training, batch_norm_decay=batch_norm_decay)\n",
    "    inputs, labels, is_training = get_inputs(batch_size=TRAIN_BATCH_SIZE)\n",
    "    with slim.arg_scope(arg_scope):\n",
    "        segnet_model.logits, predicted_annotations = inference(inputs, class_inc_bg=NUM_CLASSES)\n",
    "    segnet_model.loss = compute_loss(logits, labels)\n",
    "    segnet_model.optimizer, segnet_model.global_step = training_op(loss, learning_rate)\n",
    "    segnet_model.accuracy = compute_accuracy(logits, labels)\n",
    "    return segnet_model\n",
    "\n",
    "def segnet_model_fn(inputs, labels,mode, params):\n",
    "    \n",
    "    segnet_model = build_segnet(inputs, labels,\n",
    "                                batch_size=params['batch_size'],\n",
    "                                learning_rate = params['learning_rate'],\n",
    "                                batch_norm_decay = params['bn_decay'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pure DL Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(train_iterator.initializer)\n",
    "\n",
    "for i in range(NUM_ITERS):\n",
    "    train_image, train_labels =sess.run(train_iterator.get_next())\n",
    "    if len(train_image) < TRAIN_BATCH_SIZE:\n",
    "        sess.run(train_iterator.initializer)\n",
    "        train_image, train_labels =sess.run(train_iterator.get_next())\n",
    "    _, loss_,accuracy_ = sess.run([optimizer,loss, accuracy], feed_dict={inputs: train_image, labels:train_labels,\n",
    "                                                  is_training: True})\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(f\"Iter: {i},Loss: {loss_}, Acc:{accuracy_}\")\n",
    "        if i > 0:\n",
    "            sess.run(val_iterator.initializer)\n",
    "            val_image, val_labels = sess.run(val_iterator.get_next())\n",
    "            val_acc,preds = sess.run([accuracy,predicted_annotations],\n",
    "                                     feed_dict={inputs: val_image, labels:val_labels,\n",
    "                                                         is_training: False})\n",
    "            print(f\"Val Acc:{val_acc}\")\n",
    "            visualize_image_annot(val_image[0],val_labels[0],preds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import edward as ed\n",
    "from edward.models import Categorical, Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(tf.float32, [TRAIN_BATCH_SIZE, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH ])\n",
    "labels = tf.placeholder(tf.int32,[TRAIN_BATCH_SIZE, IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "is_training = tf.placeholder(tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segnet_simple(inputs_):\n",
    "    conv1_w = Normal(loc=tf.zeros([3,3,3,NUM_CLASSES]), scale=tf.ones([3,3,3,NUM_CLASSES]))\n",
    "    conv1_b = Normal(loc=tf.zeros([NUM_CLASSES]), scale=tf.ones([NUM_CLASSES]))\n",
    "    conv1_logit = tf.nn.conv2d(inputs_,conv1_w, strides=[1,1,1,1], padding='SAME')\n",
    "    conv1_logit = conv1_logit + conv1_b\n",
    "    predicted_mask = Categorical(logits=conv1_logit)\n",
    "    conv1_qw = Normal(loc=tf.Variable(tf.random_normal([3,3,3,NUM_CLASSES])), \n",
    "                  scale=tf.nn.softplus(tf.Variable(tf.random_normal([3,3,3,NUM_CLASSES]))))\n",
    "    conv1_qb = Normal(loc=tf.Variable(tf.random_normal([NUM_CLASSES])),\n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([NUM_CLASSES]))))\n",
    "    latent_dict = {conv1_w: conv1_qw, conv1_b: conv1_qb}\n",
    "    return predicted_mask, latent_dict\n",
    "\n",
    "predicted_mask, latent_dict = segnet_simple(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segnet_advanced(inputs_, is_training):\n",
    "    conv1_w = Normal(loc=tf.zeros([3,3,3,64]), scale=tf.ones([3,3,3,64]))\n",
    "    conv1_b = Normal(loc=tf.zeros([64]), scale=tf.ones([64]))\n",
    "    net = tf.nn.conv2d(inputs,conv1_w, strides=[1,1,1,1], padding='SAME')\n",
    "    net = net + conv1_b\n",
    "    net = tf.contrib.layers.batch_norm(net, is_training=is_training)\n",
    "    net = tf.nn.relu(net)\n",
    "    net, arg1 = tf.nn.max_pool_with_argmax(net, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    net = unpool_with_argmax(net, arg1, name='maxunpool3')\n",
    "    conv1r_w = Normal(loc=tf.zeros([3,3,64,NUM_CLASSES]), scale=tf.ones([3,3,64,NUM_CLASSES]))\n",
    "    conv1r_b = Normal(loc=tf.zeros([NUM_CLASSES]), scale=tf.ones([NUM_CLASSES]))\n",
    "    net = tf.nn.conv2d(net,conv1r_w, strides=[1,1,1,1], padding='SAME')\n",
    "    net = net + conv1r_b\n",
    "    predicted_mask = Categorical(logits=net)\n",
    "    conv1_qw = Normal(loc=tf.Variable(tf.random_normal([3,3,3,64])), \n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([3,3,3,64]))))\n",
    "    conv1_qb = Normal(loc=tf.Variable(tf.random_normal([64])),\n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([64]))))\n",
    "\n",
    "    conv1r_qw = Normal(loc=tf.Variable(tf.random_normal([3,3,64,NUM_CLASSES])), \n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([3,3,64,NUM_CLASSES]))))\n",
    "    conv1r_qb = Normal(loc=tf.Variable(tf.random_normal([NUM_CLASSES])),\n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([NUM_CLASSES]))))\n",
    "    latent_dict = {conv1_w: conv1_qw, conv1_b: conv1_qb, conv1r_w:conv1r_qw, conv1r_b: conv1r_qb }\n",
    "    \n",
    "    return predicted_mask, latent_dict\n",
    "\n",
    "predicted_mask, latent_dict = segnet_advanced(inputs, is_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segnet_advanced2(inputs_, is_training):\n",
    "    conv1_w = Normal(loc=tf.zeros([3,3,3,64]), scale=tf.ones([3,3,3,64]))\n",
    "    conv1_b = Normal(loc=tf.zeros([64]), scale=tf.ones([64]))\n",
    "    net = tf.nn.conv2d(inputs,conv1_w, strides=[1,1,1,1], padding='SAME')\n",
    "    net = net + conv1_b\n",
    "    net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "    net = tf.nn.relu(net)\n",
    "    net, arg1 = tf.nn.max_pool_with_argmax(net, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    \n",
    "    conv2_w = Normal(loc=tf.zeros([3,3,64,128]), scale=tf.ones([3,3,64,128]))\n",
    "    conv2_b = Normal(loc=tf.zeros([128]), scale=tf.ones([128]))\n",
    "    net = tf.nn.conv2d(net,conv2_w, strides=[1,1,1,1], padding='SAME')\n",
    "    net = net + conv2_b\n",
    "    net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "    net = tf.nn.relu(net)\n",
    "    net, arg2 = tf.nn.max_pool_with_argmax(net, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    conv3_w = Normal(loc=tf.zeros([3,3,128,256]), scale=tf.ones([3,3,128,256]))\n",
    "    conv3_b = Normal(loc=tf.zeros([256]), scale=tf.ones([256]))\n",
    "    net = tf.nn.conv2d(net,conv3_w, strides=[1,1,1,1], padding='SAME')\n",
    "    net = net + conv3_b\n",
    "    net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "    net = tf.nn.relu(net)\n",
    "    net, arg3 = tf.nn.max_pool_with_argmax(net, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    net = unpool_with_argmax(net, arg3, name='maxunpool_arg3')\n",
    "    conv3r_w = Normal(loc=tf.zeros([3,3,256,128]), scale=tf.ones([3,3,256,128]))\n",
    "    conv3r_b = Normal(loc=tf.zeros([128]), scale=tf.ones([128]))\n",
    "    net = tf.nn.conv2d(net,conv3r_w, strides=[1,1,1,1], padding='SAME')\n",
    "    net = net + conv3r_b\n",
    "    net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "    net = tf.nn.relu(net)\n",
    "    \n",
    "    net = unpool_with_argmax(net, arg2, name='maxunpool_arg2')\n",
    "    conv2r_w = Normal(loc=tf.zeros([3,3,128,64]), scale=tf.ones([3,3,128,64]))\n",
    "    conv2r_b = Normal(loc=tf.zeros([64]), scale=tf.ones([64]))\n",
    "    net = tf.nn.conv2d(net,conv2r_w, strides=[1,1,1,1], padding='SAME')\n",
    "    net = net + conv2r_b\n",
    "    net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "    net = tf.nn.relu(net)\n",
    "    \n",
    "    net = unpool_with_argmax(net, arg1, name='maxunpool_arg1')\n",
    "    conv1r_w = Normal(loc=tf.zeros([3,3,64,NUM_CLASSES]), scale=tf.ones([3,3,64,NUM_CLASSES]))\n",
    "    conv1r_b = Normal(loc=tf.zeros([NUM_CLASSES]), scale=tf.ones([NUM_CLASSES]))\n",
    "    net = tf.nn.conv2d(net,conv1r_w, strides=[1,1,1,1], padding='SAME')\n",
    "    net = net + conv1r_b\n",
    "    #net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "    #net = tf.nn.relu(net)\n",
    "    \n",
    "    predicted_mask = Categorical(logits=net)\n",
    "    \n",
    "    conv3_qw = Normal(loc=tf.Variable(tf.random_normal([3,3,128,256])), \n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([3,3,128,256]))))\n",
    "    conv3_qb = Normal(loc=tf.Variable(tf.random_normal([256])),\n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([256]))))\n",
    "    \n",
    "    conv3r_qw = Normal(loc=tf.Variable(tf.random_normal([3,3,256,128])), \n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([3,3,256,128]))))\n",
    "    conv3r_qb = Normal(loc=tf.Variable(tf.random_normal([128])),\n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([128]))))\n",
    "    \n",
    "    conv2_qw = Normal(loc=tf.Variable(tf.random_normal([3,3,64,128])), \n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([3,3,64,128]))))\n",
    "    conv2_qb = Normal(loc=tf.Variable(tf.random_normal([128])),\n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([128]))))\n",
    "\n",
    "    conv2r_qw = Normal(loc=tf.Variable(tf.random_normal([3,3,128,64])), \n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([3,3,128,64]))))\n",
    "    conv2r_qb = Normal(loc=tf.Variable(tf.random_normal([64])),\n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([64]))))\n",
    "    \n",
    "    conv1_qw = Normal(loc=tf.Variable(tf.random_normal([3,3,3,64])), \n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([3,3,3,64]))))\n",
    "    conv1_qb = Normal(loc=tf.Variable(tf.random_normal([64])),\n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([64]))))\n",
    "\n",
    "    conv1r_qw = Normal(loc=tf.Variable(tf.random_normal([3,3,64,NUM_CLASSES])), \n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([3,3,64,NUM_CLASSES]))))\n",
    "    conv1r_qb = Normal(loc=tf.Variable(tf.random_normal([NUM_CLASSES])),\n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([NUM_CLASSES]))))\n",
    "    \n",
    "    \n",
    "    latent_dict = {conv1_w: conv1_qw, conv1_b: conv1_qb, \n",
    "                   conv1r_w:conv1r_qw, conv1r_b: conv1r_qb,\n",
    "                   conv2_w: conv2_qw, conv2_b: conv2_qb, \n",
    "                   conv2r_w:conv2r_qw, conv2r_b: conv2r_qb,\n",
    "                   conv3_w: conv3_qw, conv3_b: conv3_qb, \n",
    "                   conv3r_w:conv3r_qw, conv3r_b: conv3r_qb\n",
    "                  }\n",
    "    \n",
    "    return predicted_mask, latent_dict\n",
    "\n",
    "predicted_mask, latent_dict = segnet_advanced2(inputs, is_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segnet_advanced3(inputs_, is_training):\n",
    "    conv1_w = Normal(loc=tf.zeros([3,3,3,64]), scale=tf.ones([3,3,3,64]))\n",
    "    conv1_b = Normal(loc=tf.zeros([64]), scale=tf.ones([64]))\n",
    "    conv11_w = Normal(loc=tf.zeros([3,3,64,64]), scale=tf.ones([3,3,64,64]))\n",
    "    conv11_b = Normal(loc=tf.zeros([64]), scale=tf.ones([64]))\n",
    "    net = tf.nn.conv2d(inputs,conv1_w, strides=[1,1,1,1], padding='SAME')\n",
    "    net = net + conv1_b\n",
    "    net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "    net = tf.nn.relu(net)\n",
    "    net = tf.nn.conv2d(net,conv11_w, strides=[1,1,1,1], padding='SAME')\n",
    "    net = net + conv11_b\n",
    "    net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "    net = tf.nn.relu(net)\n",
    "    net, arg1 = tf.nn.max_pool_with_argmax(net, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    \n",
    "    conv2_w = Normal(loc=tf.zeros([3,3,64,128]), scale=tf.ones([3,3,64,128]))\n",
    "    conv2_b = Normal(loc=tf.zeros([128]), scale=tf.ones([128]))\n",
    "    conv21_w = Normal(loc=tf.zeros([3,3,128,128]), scale=tf.ones([3,3,128,128]))\n",
    "    conv21_b = Normal(loc=tf.zeros([128]), scale=tf.ones([128]))\n",
    "    net = tf.nn.conv2d(net,conv2_w, strides=[1,1,1,1], padding='SAME')\n",
    "    net = net + conv2_b\n",
    "    net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "    net = tf.nn.relu(net)\n",
    "    net = tf.nn.conv2d(net,conv21_w, strides=[1,1,1,1], padding='SAME')\n",
    "    net = net + conv21_b\n",
    "    net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "    net = tf.nn.relu(net)\n",
    "    net, arg2 = tf.nn.max_pool_with_argmax(net, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    conv3_w = Normal(loc=tf.zeros([3,3,128,256]), scale=tf.ones([3,3,128,256]))\n",
    "    conv3_b = Normal(loc=tf.zeros([256]), scale=tf.ones([256]))\n",
    "    net = tf.nn.conv2d(net,conv3_w, strides=[1,1,1,1], padding='SAME')\n",
    "    net = net + conv3_b\n",
    "    net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "    net = tf.nn.relu(net)\n",
    "    net, arg3 = tf.nn.max_pool_with_argmax(net, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    net = unpool_with_argmax(net, arg3, name='maxunpool_arg3')\n",
    "    conv3r_w = Normal(loc=tf.zeros([3,3,256,128]), scale=tf.ones([3,3,256,128]))\n",
    "    conv3r_b = Normal(loc=tf.zeros([128]), scale=tf.ones([128]))\n",
    "    net = tf.nn.conv2d(net,conv3r_w, strides=[1,1,1,1], padding='SAME')\n",
    "    net = net + conv3r_b\n",
    "    net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "    net = tf.nn.relu(net)\n",
    "    \n",
    "    net = unpool_with_argmax(net, arg2, name='maxunpool_arg2')\n",
    "    conv21r_w = Normal(loc=tf.zeros([3,3,128,128]), scale=tf.ones([3,3,128,128]))\n",
    "    conv21r_b = Normal(loc=tf.zeros([128]), scale=tf.ones([128]))\n",
    "    net = tf.nn.conv2d(net,conv21r_w, strides=[1,1,1,1], padding='SAME')\n",
    "    net = net + conv21r_b\n",
    "    net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "    net = tf.nn.relu(net)\n",
    "    conv2r_w = Normal(loc=tf.zeros([3,3,128,64]), scale=tf.ones([3,3,128,64]))\n",
    "    conv2r_b = Normal(loc=tf.zeros([64]), scale=tf.ones([64]))\n",
    "    net = tf.nn.conv2d(net,conv2r_w, strides=[1,1,1,1], padding='SAME')\n",
    "    net = net + conv2r_b\n",
    "    net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "    net = tf.nn.relu(net)\n",
    "    \n",
    "    net = unpool_with_argmax(net, arg1, name='maxunpool_arg1')\n",
    "    conv11r_w = Normal(loc=tf.zeros([3,3,64,64]), scale=tf.ones([3,3,64,64]))\n",
    "    conv11r_b = Normal(loc=tf.zeros([64]), scale=tf.ones([64]))\n",
    "    net = tf.nn.conv2d(net,conv11r_w, strides=[1,1,1,1], padding='SAME')\n",
    "    net = net + conv11r_b\n",
    "    net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "    net = tf.nn.relu(net)\n",
    "    conv1r_w = Normal(loc=tf.zeros([3,3,64,NUM_CLASSES]), scale=tf.ones([3,3,64,NUM_CLASSES]))\n",
    "    conv1r_b = Normal(loc=tf.zeros([NUM_CLASSES]), scale=tf.ones([NUM_CLASSES]))\n",
    "    net = tf.nn.conv2d(net,conv1r_w, strides=[1,1,1,1], padding='SAME')\n",
    "    net = net + conv1r_b\n",
    "    #net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "    #net = tf.nn.relu(net)\n",
    "    \n",
    "    predicted_mask = Categorical(logits=net)\n",
    "    \n",
    "    conv3_qw = Normal(loc=tf.Variable(tf.random_normal([3,3,128,256])), \n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([3,3,128,256]))))\n",
    "    conv3_qb = Normal(loc=tf.Variable(tf.random_normal([256])),\n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([256]))))\n",
    "    \n",
    "    conv3r_qw = Normal(loc=tf.Variable(tf.random_normal([3,3,256,128])), \n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([3,3,256,128]))))\n",
    "    conv3r_qb = Normal(loc=tf.Variable(tf.random_normal([128])),\n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([128]))))\n",
    "    \n",
    "    conv2_qw = Normal(loc=tf.Variable(tf.random_normal([3,3,64,128])), \n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([3,3,64,128]))))\n",
    "    conv2_qb = Normal(loc=tf.Variable(tf.random_normal([128])),\n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([128]))))\n",
    "    conv21_qw = Normal(loc=tf.Variable(tf.random_normal([3,3,128,128])), \n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([3,3,128,128]))))\n",
    "    conv21_qb = Normal(loc=tf.Variable(tf.random_normal([128])),\n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([128]))))\n",
    "\n",
    "    conv21r_qw = Normal(loc=tf.Variable(tf.random_normal([3,3,128,128])), \n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([3,3,128,128]))))\n",
    "    conv21r_qb = Normal(loc=tf.Variable(tf.random_normal([128])),\n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([128]))))\n",
    "    \n",
    "    conv2r_qw = Normal(loc=tf.Variable(tf.random_normal([3,3,128,64])), \n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([3,3,128,64]))))\n",
    "    conv2r_qb = Normal(loc=tf.Variable(tf.random_normal([64])),\n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([64]))))\n",
    "    \n",
    "    conv1_qw = Normal(loc=tf.Variable(tf.random_normal([3,3,3,64])), \n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([3,3,3,64]))))\n",
    "    conv1_qb = Normal(loc=tf.Variable(tf.random_normal([64])),\n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([64]))))\n",
    "    \n",
    "    conv11_qw = Normal(loc=tf.Variable(tf.random_normal([3,3,64,64])), \n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([3,3,64,64]))))\n",
    "    conv11_qb = Normal(loc=tf.Variable(tf.random_normal([64])),\n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([64]))))\n",
    "    \n",
    "    conv11r_qw = Normal(loc=tf.Variable(tf.random_normal([3,3,64,64])), \n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([3,3,64,64]))))\n",
    "    conv11r_qb = Normal(loc=tf.Variable(tf.random_normal([64])),\n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([64]))))\n",
    "\n",
    "    conv1r_qw = Normal(loc=tf.Variable(tf.random_normal([3,3,64,NUM_CLASSES])), \n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([3,3,64,NUM_CLASSES]))))\n",
    "    conv1r_qb = Normal(loc=tf.Variable(tf.random_normal([NUM_CLASSES])),\n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([NUM_CLASSES]))))\n",
    "    \n",
    "    \n",
    "    latent_dict = {conv1_w: conv1_qw, conv1_b: conv1_qb, \n",
    "                   conv11_w: conv11_qw, conv11_b: conv11_qb, \n",
    "                   conv1r_w:conv1r_qw, conv1r_b: conv1r_qb,\n",
    "                   conv11r_w:conv11r_qw, conv11r_b: conv11r_qb,\n",
    "                   conv2_w: conv2_qw, conv2_b: conv2_qb, \n",
    "                   conv21_w: conv21_qw, conv21_b: conv21_qb,\n",
    "                   conv21r_w:conv21r_qw, conv21r_b: conv21r_qb,\n",
    "                   conv2r_w:conv2r_qw, conv2r_b: conv2r_qb,\n",
    "                   conv3_w: conv3_qw, conv3_b: conv3_qb, \n",
    "                   conv3r_w:conv3r_qw, conv3r_b: conv3r_qb\n",
    "                  }\n",
    "    \n",
    "    return predicted_mask, latent_dict\n",
    "\n",
    "predicted_mask, latent_dict = segnet_advanced3(inputs, is_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<ed.RandomVariable 'Normal_2/' shape=(3, 3, 3, 64) dtype=float32>: <ed.RandomVariable 'Normal_62/' shape=(3, 3, 3, 64) dtype=float32>,\n",
       " <ed.RandomVariable 'Normal_5/' shape=(64,) dtype=float32>: <ed.RandomVariable 'Normal_65/' shape=(64,) dtype=float32>,\n",
       " <ed.RandomVariable 'Normal_32/' shape=(3, 3, 64, 12) dtype=float32>: <ed.RandomVariable 'Normal_68/' shape=(3, 3, 64, 12) dtype=float32>,\n",
       " <ed.RandomVariable 'Normal_35/' shape=(12,) dtype=float32>: <ed.RandomVariable 'Normal_71/' shape=(12,) dtype=float32>,\n",
       " <ed.RandomVariable 'Normal_8/' shape=(3, 3, 64, 128) dtype=float32>: <ed.RandomVariable 'Normal_50/' shape=(3, 3, 64, 128) dtype=float32>,\n",
       " <ed.RandomVariable 'Normal_11/' shape=(128,) dtype=float32>: <ed.RandomVariable 'Normal_53/' shape=(128,) dtype=float32>,\n",
       " <ed.RandomVariable 'Normal_26/' shape=(3, 3, 128, 64) dtype=float32>: <ed.RandomVariable 'Normal_56/' shape=(3, 3, 128, 64) dtype=float32>,\n",
       " <ed.RandomVariable 'Normal_29/' shape=(64,) dtype=float32>: <ed.RandomVariable 'Normal_59/' shape=(64,) dtype=float32>,\n",
       " <ed.RandomVariable 'Normal_14/' shape=(3, 3, 128, 256) dtype=float32>: <ed.RandomVariable 'Normal_38/' shape=(3, 3, 128, 256) dtype=float32>,\n",
       " <ed.RandomVariable 'Normal_17/' shape=(256,) dtype=float32>: <ed.RandomVariable 'Normal_41/' shape=(256,) dtype=float32>,\n",
       " <ed.RandomVariable 'Normal_20/' shape=(3, 3, 256, 128) dtype=float32>: <ed.RandomVariable 'Normal_44/' shape=(3, 3, 256, 128) dtype=float32>,\n",
       " <ed.RandomVariable 'Normal_23/' shape=(128,) dtype=float32>: <ed.RandomVariable 'Normal_47/' shape=(128,) dtype=float32>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inference = ed.KLqp(latent_dict, data={predicted_mask: labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = NUM_TRAIN\n",
    "M = TRAIN_BATCH_SIZE\n",
    "n_batch=int(N/M)\n",
    "n_epoch = 150\n",
    "loss = []\n",
    "inference.initialize(n_iter=n_batch*n_epoch, n_samples=5, scale={predicted_mask: N/M})\n",
    "saver = tf.train.Saver()\n",
    "sess = ed.get_session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(train_iterator.initializer)\n",
    "for i in range(inference.n_iter):\n",
    "    train_image, train_labels =sess.run(train_iterator.get_next())\n",
    "    if len(train_image) < TRAIN_BATCH_SIZE:\n",
    "        sess.run(train_iterator.initializer)\n",
    "        train_image, train_labels =sess.run(train_iterator.get_next())\n",
    "    info_dict = inference.update({inputs: train_image, labels: train_labels, is_training: True})\n",
    "    inference.print_progress(info_dict)\n",
    "    loss.append(info_dict['loss'])\n",
    "    if info_dict['loss'] < 0.8e+6:\n",
    "        print(i)\n",
    "        break\n",
    "saver.save(sess, \"tmp/test_saver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tmp/test_saver\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Assign requires shapes of both tensors to match. lhs shape= [3,3,3,64] rhs shape= [3,3,128,128]\n\t [[Node: save/Assign_23 = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_16\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Variable_16, save/RestoreV2_23/_15)]]\n\nCaused by op 'save/Assign_23', defined at:\n  File \"/home/aravind/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/aravind/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-ad8ec01d825a>\", line 2, in <module>\n    saver = tf.train.Saver()\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1140, in __init__\n    self.build()\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1172, in build\n    filename=self._filename)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 688, in build\n    restore_sequentially, reshape)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(tensors, shapes))\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 155, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 274, in assign\n    validate_shape=validate_shape)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 43, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [3,3,3,64] rhs shape= [3,3,128,128]\n\t [[Node: save/Assign_23 = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_16\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Variable_16, save/RestoreV2_23/_15)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aravind/anaconda3/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [3,3,3,64] rhs shape= [3,3,128,128]\n\t [[Node: save/Assign_23 = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_16\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Variable_16, save/RestoreV2_23/_15)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ad8ec01d825a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0med\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tmp/test_saver\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restoring parameters from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1560\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [3,3,3,64] rhs shape= [3,3,128,128]\n\t [[Node: save/Assign_23 = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_16\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Variable_16, save/RestoreV2_23/_15)]]\n\nCaused by op 'save/Assign_23', defined at:\n  File \"/home/aravind/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/aravind/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-ad8ec01d825a>\", line 2, in <module>\n    saver = tf.train.Saver()\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1140, in __init__\n    self.build()\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1172, in build\n    filename=self._filename)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 688, in build\n    restore_sequentially, reshape)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(tensors, shapes))\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 155, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 274, in assign\n    validate_shape=validate_shape)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 43, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/aravind/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [3,3,3,64] rhs shape= [3,3,128,128]\n\t [[Node: save/Assign_23 = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_16\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Variable_16, save/RestoreV2_23/_15)]]\n"
     ]
    }
   ],
   "source": [
    "sess = ed.get_session()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"tmp/test_saver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(val_iterator.initializer)\n",
    "val_image, val_labels =sess.run(val_iterator.get_next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = np.array(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bayes_visualize_image_annot(img_data, annot_data, predicted_annot, ax, n_samples=20):\n",
    "    ax[0].imshow(img_data)\n",
    "    ax[0].set_title('Original Image')\n",
    "    ax[1].imshow(img_annot_to_rgb(predicted_annot), alpha=0.1)\n",
    "    ax[1].set_title('Posterior Predicted Segmentation %d samples' % n_samples)\n",
    "    ax[2].imshow(img_annot_to_rgb(annot_data))\n",
    "    ax[2].set_title('True Segmentation')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ppc_nsamples=100\n",
    "predicted_mask_post = ed.copy(predicted_mask, latent_dict)\n",
    "predicted_mask_post_samples = predicted_mask_post.sample(ppc_nsamples)\n",
    "ppc=sess.run(predicted_mask_post_samples,\n",
    "             feed_dict={inputs: val_image, predicted_mask: val_labels, is_training: True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=31\n",
    "fig, ax = plt.subplots(1,3,figsize=(10,12))\n",
    "for j in range(20):\n",
    "    bayes_visualize_image_annot(val_image[idx], val_labels[idx],ppc[j,idx],ax, n_samples=ppc_nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
