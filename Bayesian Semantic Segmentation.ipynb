{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Semantic Segmentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic Segmentation has been a challenging task in computer vision and has seen\n",
    "limited progress till the advent of neural networks (Badrinarayanan et al., 2015). The goal of\n",
    "semantic segmentation is to label every pixel of an image with a predefined class and this is\n",
    "useful for object detection, background elimination and for machine learning tasks downstream.\n",
    "The issue with neural networks for segmentation however is that they are prone to overfitting,\n",
    "the predictions are not calibrated effectively, the models are highly sensitive to class imbalances\n",
    "and to minor changes in data distribution during evaluation. We hope to adopt a full Bayesian\n",
    "approach to semantic segmentation (Badrinarayanan et al., 2016) to alleviate these concerns\n",
    "leveraging recent developments in probabilistic programming tools like Edward, techniques like\n",
    "stochastic BBVI together with neural network as function approximators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need for Bayesian Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  a) Need for proper output Uncertainity\n",
    "\n",
    "MLE estimates combined with Softmax class probabilties do not represent true uncertainity and typically are overconfident of the predictions   (e.g. see Figure 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title1](img/crash.jpg)\n",
    "#### Figure 1.                Tesla  Model S Crash (May 2016) - Perception System confused a white trailer for sky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Handling Out of train distribution\n",
    "\n",
    "MLE Estimates perform very poorly if the test distribution differs a lot from training distribution. This raises concerns with how automated system will perform as there is no gurantee that a test sample will be close to training distribution (see Figure 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title1](img/test_distrib.png)\n",
    "#### Figure 2.                Using a Model trained on UK to test a sample from a different country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Need for probability calibration\n",
    "\n",
    "For machine learning systems, output of one model needs to be fed to another model. This requires proper calibration of estimates together with associated uncertainity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we have chosen is the popular CamVid dataset (Brostow, Shotton, et al., 2008;\n",
    "Brostow, Fauqueur, & Cipolla, 2008). The dataset contains still images from video footage\n",
    "from a driving automobile around Cambridge (UK). We will be using a subset of the dataset\n",
    "rescaled to 360x480 pixels and labels are semantically labeled with 12 classes (Figure3: Sky, Building,\n",
    "Pole, Road, Pavement, Tree, SignSymbol, Fence, Car, Pedestrian, Bicyclist,\n",
    "Unlabeled). Due to computational constraints, we rescale the image and labels further to 72x96\n",
    "pixels. This dataset presents very interesting challenges and relevance to the project because of a)\n",
    "Lower number of training examples and low resolution b) There is high class imbalance between\n",
    "categories and low frequency classes are most important for detection tasks (e.g pedestrians\n",
    "occur 340 times less frequently compared to sky/building) c) There is lot of prior information\n",
    "structure that can be incorporated in to a Bayesian model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title1](img/colormap.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 3 - Output Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imread\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from segnet_utils import unpool_with_argmax, get_label_colors, img_annot_to_rgb\n",
    "from segnet_utils import visualize_image_annot, bayes_visualize_image_annot\n",
    "from segnet_utils import plot_uncertainity_from_posterior\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'CamVid/train.txt'\n",
    "val_file = 'CamVid/val.txt'\n",
    "test_file = 'CamVid/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT = 72\n",
    "IMAGE_WIDTH = 96\n",
    "IMAGE_DEPTH = 3\n",
    "NUM_CLASSES = 12\n",
    "TRAIN_BATCH_SIZE=32\n",
    "VAL_BATCH_SIZE=TRAIN_BATCH_SIZE\n",
    "TEST_BATCH_SIZE = TRAIN_BATCH_SIZE\n",
    "NUM_ITERS = 2000\n",
    "NUM_TRAIN = 367\n",
    "NUM_VAL = 101\n",
    "NUM_TEST = 233"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file, train=True, batch_size=10, labels=True):\n",
    "    def _load_image(filename):\n",
    "        image_string = tf.read_file(filenames[0])\n",
    "        image_decoded = tf.image.decode_png(image_string, channels=3)\n",
    "        image_decoded = tf.image.convert_image_dtype(image_decoded,tf.float32)\n",
    "        return image_decoded\n",
    "\n",
    "    def _load_image_with_labels(filenames):\n",
    "        image_string = tf.read_file(filenames[0])\n",
    "        image_decoded = tf.image.decode_png(image_string, channels=3)\n",
    "        image_decoded = tf.image.convert_image_dtype(image_decoded,tf.float32)\n",
    "        image_decoded = tf.image.resize_images(image_decoded, [IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "        annot_string = tf.read_file(filenames[1])\n",
    "        annot_decoded = tf.image.decode_png(annot_string, channels=1)\n",
    "        annot_decoded = tf.image.resize_images(annot_decoded, [IMAGE_HEIGHT,IMAGE_WIDTH])\n",
    "        annot_decoded = tf.squeeze(annot_decoded,axis=2)\n",
    "        annot_decoded = tf.cast(annot_decoded, tf.int64)\n",
    "        return image_decoded, annot_decoded\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(tf.constant([file]))\n",
    "    dataset =  dataset.flat_map(lambda filename: tf.data.TextLineDataset(filename))\n",
    "    dataset = dataset.map(lambda line: tf.string_split([line], delimiter=' ').values)\n",
    "    if labels:\n",
    "        dataset = dataset.map(_load_image_with_labels)\n",
    "    else:\n",
    "        dataset = dataset.map(_load_image)\n",
    "    if train is True:\n",
    "        dataset = dataset.shuffle(buffer_size=batch_size*3)\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    return iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "train_iterator = load_data(train_file, batch_size=TRAIN_BATCH_SIZE)\n",
    "val_iterator = load_data(val_file, train=False, batch_size=TRAIN_BATCH_SIZE)\n",
    "test_iterator = load_data(test_file, train=False, batch_size=TRAIN_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differing from the Dropout VI approach that formulates Dropout layers as a form of Bayesian\n",
    "approximation (Badrinarayanan et al., 2016), our approach is to cycle through Box’s loop to\n",
    "develop models that are less prone to overfitting, incorporate prior information, deal with class\n",
    "imbalance and produce well calibrated predictions and model uncertainty. Inference though\n",
    "stochastic methods will be interesting as we encounter convergence issues and hyperparameter\n",
    "tuning. Criticism is the most interesting part of our analysis for a computer vision task as we as\n",
    "humans can easily judge whether the prediction uncertainties make sense.\n",
    "The following figure summarizes Box’s loop for our project in a succinct manner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$segment_{ij} \\sim Categorical(logits=NN) $\n",
    "\n",
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![title](img/conv_net2.png)]\n",
    "### Figure 3 Convolutional Net Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edward as ed\n",
    "from edward.models import Categorical, Normal, Empirical, StudentT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(tf.float32, [TRAIN_BATCH_SIZE, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH ])\n",
    "labels = tf.placeholder(tf.int32,[TRAIN_BATCH_SIZE, IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "is_training = tf.placeholder(tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(inputs_, is_training):\n",
    "    conv1_w = StudentT(loc=tf.zeros([3,3,3,64]), scale=tf.ones([3,3,3,64]),df=1.0)\n",
    "    conv1_b = StudentT(loc=tf.zeros([64]), scale=tf.ones([64]),df=1.0)\n",
    "    net = tf.nn.conv2d(inputs,conv1_w, strides=[1,1,1,1], padding='SAME')\n",
    "    net = net + conv1_b\n",
    "    net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "    net = tf.nn.relu(net)\n",
    "    net, arg1 = tf.nn.max_pool_with_argmax(net, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    \n",
    "    conv2_w = StudentT(loc=tf.zeros([3,3,64,128]), scale=tf.ones([3,3,64,128]),df=1.0)\n",
    "    conv2_b = StudentT(loc=tf.zeros([128]), scale=tf.ones([128]),df=1.0)\n",
    "    net = tf.nn.conv2d(net,conv2_w, strides=[1,1,1,1], padding='SAME')\n",
    "    net = net + conv2_b\n",
    "    net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "    net = tf.nn.relu(net)\n",
    "    net, arg2 = tf.nn.max_pool_with_argmax(net, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    conv3_w = StudentT(loc=tf.zeros([3,3,128,256]), scale=tf.ones([3,3,128,256]),df=1.0)\n",
    "    conv3_b = StudentT(loc=tf.zeros([256]), scale=tf.ones([256]),df=1.0)\n",
    "    net = tf.nn.conv2d(net,conv3_w, strides=[1,1,1,1], padding='SAME')\n",
    "    net = net + conv3_b\n",
    "    net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "    net = tf.nn.relu(net)\n",
    "    net, arg3 = tf.nn.max_pool_with_argmax(net, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    net = unpool_with_argmax(net, arg3, name='maxunpool_arg3')\n",
    "    conv3r_w = StudentT(loc=tf.zeros([3,3,256,128]), scale=tf.ones([3,3,256,128]),df=1.0)\n",
    "    conv3r_b = StudentT(loc=tf.zeros([128]), scale=tf.ones([128]),df=1.0)\n",
    "    net = tf.nn.conv2d(net,conv3r_w, strides=[1,1,1,1], padding='SAME')\n",
    "    net = net + conv3r_b\n",
    "    net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "    net = tf.nn.relu(net)\n",
    "    \n",
    "    net = unpool_with_argmax(net, arg2, name='maxunpool_arg2')\n",
    "    conv2r_w = StudentT(loc=tf.zeros([3,3,128,64]), scale=tf.ones([3,3,128,64]),df=1.0)\n",
    "    conv2r_b = StudentT(loc=tf.zeros([64]), scale=tf.ones([64]),df=1.0)\n",
    "    net = tf.nn.conv2d(net,conv2r_w, strides=[1,1,1,1], padding='SAME')\n",
    "    net = net + conv2r_b\n",
    "    net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "    net = tf.nn.relu(net)\n",
    "    \n",
    "    net = unpool_with_argmax(net, arg1, name='maxunpool_arg1')\n",
    "    conv1r_w = StudentT(loc=tf.zeros([3,3,64,NUM_CLASSES]), scale=tf.ones([3,3,64,NUM_CLASSES]),df=1.0)\n",
    "    conv1r_b = StudentT(loc=tf.zeros([NUM_CLASSES]), scale=tf.ones([NUM_CLASSES]),df=1.0)\n",
    "    net = tf.nn.conv2d(net,conv1r_w, strides=[1,1,1,1], padding='SAME')\n",
    "    net = net + conv1r_b\n",
    "    #net = tf.contrib.layers.batch_norm(net, is_training=is_training, decay=0.99)\n",
    "    #net = tf.nn.relu(net)\n",
    "    \n",
    "    predicted_mask = Categorical(logits=net)\n",
    "    \n",
    "    conv3_qw = Normal(loc=tf.Variable(tf.random_normal([3,3,128,256])), \n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([3,3,128,256]))))\n",
    "    conv3_qb = Normal(loc=tf.Variable(tf.random_normal([256])),\n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([256]))))\n",
    "    \n",
    "    conv3r_qw = Normal(loc=tf.Variable(tf.random_normal([3,3,256,128])), \n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([3,3,256,128]))))\n",
    "    conv3r_qb = Normal(loc=tf.Variable(tf.random_normal([128])),\n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([128]))))\n",
    "    \n",
    "    conv2_qw = Normal(loc=tf.Variable(tf.random_normal([3,3,64,128])), \n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([3,3,64,128]))))\n",
    "    conv2_qb = Normal(loc=tf.Variable(tf.random_normal([128])),\n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([128]))))\n",
    "\n",
    "    conv2r_qw = Normal(loc=tf.Variable(tf.random_normal([3,3,128,64])), \n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([3,3,128,64]))))\n",
    "    conv2r_qb = Normal(loc=tf.Variable(tf.random_normal([64])),\n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([64]))))\n",
    "    \n",
    "    conv1_qw = Normal(loc=tf.Variable(tf.random_normal([3,3,3,64])), \n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([3,3,3,64]))))\n",
    "    conv1_qb = Normal(loc=tf.Variable(tf.random_normal([64])),\n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([64]))))\n",
    "\n",
    "    conv1r_qw = Normal(loc=tf.Variable(tf.random_normal([3,3,64,NUM_CLASSES])), \n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([3,3,64,NUM_CLASSES]))))\n",
    "    conv1r_qb = Normal(loc=tf.Variable(tf.random_normal([NUM_CLASSES])),\n",
    "                          scale=tf.nn.softplus(tf.Variable(tf.random_normal([NUM_CLASSES]))))\n",
    "    \n",
    "    \n",
    "    latent_dict = {conv1_w: conv1_qw, conv1_b: conv1_qb, \n",
    "                   conv1r_w:conv1r_qw, conv1r_b: conv1r_qb,\n",
    "                   conv2_w: conv2_qw, conv2_b: conv2_qb, \n",
    "                   conv2r_w:conv2r_qw, conv2r_b: conv2r_qb,\n",
    "                   conv3_w: conv3_qw, conv3_b: conv3_qb, \n",
    "                   conv3r_w:conv3r_qw, conv3r_b: conv3r_qb\n",
    "                  }\n",
    "    \n",
    "    return predicted_mask, latent_dict\n",
    "\n",
    "predicted_mask, latent_dict = model(inputs, is_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ed.RandomVariable 'Categorical/' shape=(32, 72, 96) dtype=int32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(predicted_mask, latent_dict, labels, n_epoch=200,session_dir='tmp/inference',restore_sess=False):\n",
    "    \n",
    "    N = NUM_TRAIN\n",
    "    M = TRAIN_BATCH_SIZE\n",
    "    n_batch=int(N/M)\n",
    "    loss = []\n",
    "    if restore_sess:\n",
    "        sess = ed.get_session()\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, session_dir)\n",
    "        return\n",
    "    else:\n",
    "        inference = ed.KLqp(latent_dict, data={predicted_mask: labels})\n",
    "        inference.initialize(n_iter=n_batch*n_epoch, n_samples=5, scale={predicted_mask: N/M})\n",
    "        saver = tf.train.Saver()\n",
    "        sess = ed.get_session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(train_iterator.initializer)\n",
    "        for i in range(inference.n_iter):\n",
    "            train_image, train_labels =sess.run(train_iterator.get_next())\n",
    "            if len(train_image) < TRAIN_BATCH_SIZE:\n",
    "                sess.run(train_iterator.initializer)\n",
    "                train_image, train_labels =sess.run(train_iterator.get_next())\n",
    "            info_dict = inference.update({inputs: train_image, labels: train_labels, is_training: True})\n",
    "            inference.print_progress(info_dict)\n",
    "            loss.append(info_dict['loss'])\n",
    "        saver.save(sess, session_dir)\n",
    "        loss = np.array(loss)\n",
    "        plt.plot(loss[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<ed.RandomVariable 'StudentT/' shape=(3, 3, 3, 64) dtype=float32>: <ed.RandomVariable 'Normal_8/' shape=(3, 3, 3, 64) dtype=float32>,\n",
       " <ed.RandomVariable 'StudentT_1/' shape=(64,) dtype=float32>: <ed.RandomVariable 'Normal_9/' shape=(64,) dtype=float32>,\n",
       " <ed.RandomVariable 'StudentT_10/' shape=(3, 3, 64, 12) dtype=float32>: <ed.RandomVariable 'Normal_10/' shape=(3, 3, 64, 12) dtype=float32>,\n",
       " <ed.RandomVariable 'StudentT_11/' shape=(12,) dtype=float32>: <ed.RandomVariable 'Normal_11/' shape=(12,) dtype=float32>,\n",
       " <ed.RandomVariable 'StudentT_2/' shape=(3, 3, 64, 128) dtype=float32>: <ed.RandomVariable 'Normal_4/' shape=(3, 3, 64, 128) dtype=float32>,\n",
       " <ed.RandomVariable 'StudentT_3/' shape=(128,) dtype=float32>: <ed.RandomVariable 'Normal_5/' shape=(128,) dtype=float32>,\n",
       " <ed.RandomVariable 'StudentT_4/' shape=(3, 3, 128, 256) dtype=float32>: <ed.RandomVariable 'Normal/' shape=(3, 3, 128, 256) dtype=float32>,\n",
       " <ed.RandomVariable 'StudentT_5/' shape=(256,) dtype=float32>: <ed.RandomVariable 'Normal_1/' shape=(256,) dtype=float32>,\n",
       " <ed.RandomVariable 'StudentT_6/' shape=(3, 3, 256, 128) dtype=float32>: <ed.RandomVariable 'Normal_2/' shape=(3, 3, 256, 128) dtype=float32>,\n",
       " <ed.RandomVariable 'StudentT_7/' shape=(128,) dtype=float32>: <ed.RandomVariable 'Normal_3/' shape=(128,) dtype=float32>,\n",
       " <ed.RandomVariable 'StudentT_8/' shape=(3, 3, 128, 64) dtype=float32>: <ed.RandomVariable 'Normal_6/' shape=(3, 3, 128, 64) dtype=float32>,\n",
       " <ed.RandomVariable 'StudentT_9/' shape=(64,) dtype=float32>: <ed.RandomVariable 'Normal_7/' shape=(64,) dtype=float32>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/checkpoint_final\n"
     ]
    }
   ],
   "source": [
    "inference(predicted_mask, latent_dict, labels, session_dir='checkpoints/checkpoint_final',restore_sess=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CRITICISM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criticism(predicted_mask, latent_dict, data_iterator, num_samples, ppc_nsamples=100,\n",
    "              plot_one_batch_only = False, plot_random_index_per_batch=False):\n",
    "    predicted_mask_post = ed.copy(predicted_mask, latent_dict)\n",
    "    predicted_mask_post_samples = predicted_mask_post.sample(ppc_nsamples)\n",
    "    sess = ed.get_session()\n",
    "    sess.run(data_iterator.initializer)\n",
    "    num_batches = num_samples // TRAIN_BATCH_SIZE\n",
    "    for i in range(num_batches):\n",
    "        images, labels = sess.run(data_iterator.get_next())\n",
    "        ppc=sess.run(predicted_mask_post_samples,\n",
    "                 feed_dict={inputs: images, predicted_mask: labels, is_training: True})\n",
    "        \n",
    "        if plot_random_index_per_batch:\n",
    "            idx = np.random.choice(TRAIN_BATCH_SIZE,size=1)[0]\n",
    "            print(idx)\n",
    "            fig, ax = plt.subplots(1,3,figsize=(10,12))\n",
    "            for j in range(ppc_nsamples):\n",
    "                bayes_visualize_image_annot(images[idx], labels[idx],ppc[j,idx],ax, n_samples=ppc_nsamples)\n",
    "            plot_uncertainity_from_posterior(ppc,idx,ppc_nsamples)\n",
    "        else:\n",
    "            for idx in range(TRAIN_BATCH_SIZE):\n",
    "                fig, ax = plt.subplots(1,3,figsize=(10,12))\n",
    "                for j in range(ppc_nsamples):\n",
    "                    bayes_visualize_image_annot(images[idx], labels[idx],ppc[j,idx],ax, n_samples=ppc_nsamples)\n",
    "                plot_uncertainity_from_posterior(ppc,idx,ppc_nsamples)\n",
    "        if plot_one_batch_only:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "No OpKernel was registered to support Op 'MaxPoolWithArgmax' with these attrs.  Registered devices: [CPU], Registered kernels:\n  <no registered kernels>\n\n\t [[Node: copied/MaxPoolWithArgmax = MaxPoolWithArgmax[T=DT_FLOAT, Targmax=DT_INT64, ksize=[1, 2, 2, 1], padding=\"SAME\", strides=[1, 2, 2, 1]](copied/Relu)]]\n\nCaused by op 'copied/MaxPoolWithArgmax', defined at:\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-8f84b67b4d44>\", line 2, in <module>\n    plot_random_index_per_batch=False)\n  File \"<ipython-input-13-99e89681b12a>\", line 3, in criticism\n    predicted_mask_post = ed.copy(predicted_mask, latent_dict)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 244, in copy\n    value, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 86, in _copy_default\n    x = copy(x, *args, **kwargs)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 268, in copy\n    new_op = copy(op, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 332, in copy\n    elem = copy(x, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 268, in copy\n    new_op = copy(op, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 332, in copy\n    elem = copy(x, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 268, in copy\n    new_op = copy(op, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 332, in copy\n    elem = copy(x, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 268, in copy\n    new_op = copy(op, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 332, in copy\n    elem = copy(x, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 268, in copy\n    new_op = copy(op, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 332, in copy\n    elem = copy(x, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 268, in copy\n    new_op = copy(op, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 332, in copy\n    elem = copy(x, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 268, in copy\n    new_op = copy(op, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 314, in copy\n    op_def)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'MaxPoolWithArgmax' with these attrs.  Registered devices: [CPU], Registered kernels:\n  <no registered kernels>\n\n\t [[Node: copied/MaxPoolWithArgmax = MaxPoolWithArgmax[T=DT_FLOAT, Targmax=DT_INT64, ksize=[1, 2, 2, 1], padding=\"SAME\", strides=[1, 2, 2, 1]](copied/Relu)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/seg-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/seg-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/seg-env/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'MaxPoolWithArgmax' with these attrs.  Registered devices: [CPU], Registered kernels:\n  <no registered kernels>\n\n\t [[Node: copied/MaxPoolWithArgmax = MaxPoolWithArgmax[T=DT_FLOAT, Targmax=DT_INT64, ksize=[1, 2, 2, 1], padding=\"SAME\", strides=[1, 2, 2, 1]](copied/Relu)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8f84b67b4d44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m criticism(predicted_mask, latent_dict, test_iterator,NUM_TEST, plot_one_batch_only=True, \n\u001b[0;32m----> 2\u001b[0;31m           plot_random_index_per_batch=False)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-99e89681b12a>\u001b[0m in \u001b[0;36mcriticism\u001b[0;34m(predicted_mask, latent_dict, data_iterator, num_samples, ppc_nsamples, plot_one_batch_only, plot_random_index_per_batch)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         ppc=sess.run(predicted_mask_post_samples,\n\u001b[0;32m---> 11\u001b[0;31m                  feed_dict={inputs: images, predicted_mask: labels, is_training: True})\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mplot_random_index_per_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/seg-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/seg-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/seg-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/seg-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'MaxPoolWithArgmax' with these attrs.  Registered devices: [CPU], Registered kernels:\n  <no registered kernels>\n\n\t [[Node: copied/MaxPoolWithArgmax = MaxPoolWithArgmax[T=DT_FLOAT, Targmax=DT_INT64, ksize=[1, 2, 2, 1], padding=\"SAME\", strides=[1, 2, 2, 1]](copied/Relu)]]\n\nCaused by op 'copied/MaxPoolWithArgmax', defined at:\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-8f84b67b4d44>\", line 2, in <module>\n    plot_random_index_per_batch=False)\n  File \"<ipython-input-13-99e89681b12a>\", line 3, in criticism\n    predicted_mask_post = ed.copy(predicted_mask, latent_dict)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 244, in copy\n    value, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 86, in _copy_default\n    x = copy(x, *args, **kwargs)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 268, in copy\n    new_op = copy(op, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 332, in copy\n    elem = copy(x, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 268, in copy\n    new_op = copy(op, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 332, in copy\n    elem = copy(x, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 268, in copy\n    new_op = copy(op, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 332, in copy\n    elem = copy(x, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 268, in copy\n    new_op = copy(op, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 332, in copy\n    elem = copy(x, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 268, in copy\n    new_op = copy(op, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 332, in copy\n    elem = copy(x, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 268, in copy\n    new_op = copy(op, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 332, in copy\n    elem = copy(x, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 268, in copy\n    new_op = copy(op, dict_swap, scope, True, copy_q, False)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/edward/util/random_variables.py\", line 314, in copy\n    op_def)\n  File \"/Users/aravinds/seg-env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'MaxPoolWithArgmax' with these attrs.  Registered devices: [CPU], Registered kernels:\n  <no registered kernels>\n\n\t [[Node: copied/MaxPoolWithArgmax = MaxPoolWithArgmax[T=DT_FLOAT, Targmax=DT_INT64, ksize=[1, 2, 2, 1], padding=\"SAME\", strides=[1, 2, 2, 1]](copied/Relu)]]\n"
     ]
    }
   ],
   "source": [
    "criticism(predicted_mask, latent_dict, test_iterator,NUM_TEST, plot_one_batch_only=True, \n",
    "          plot_random_index_per_batch=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. REFERENCES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Badrinarayanan, V., Kendall, A., & Cipolla, R. (2015). Segnet: A deep convolutional encoder-\n",
    "decoder architecture for image segmentation. CoRR, abs/1511.00561. Retrieved from\n",
    "http://arxiv.org/pdf/1511.00561.pdf\n",
    "\n",
    "Badrinarayanan, V., Kendall, A., & Cipolla, R. (2016). Bayesian segnet: Model uncer-\n",
    "tainty in deep convolutional encoder-decoder architectures for scene understanding. CoRR,\n",
    "abs/1511.02680. Retrieved from http://arxiv.org/pdf/1511.02680.pdf\n",
    "\n",
    "Brostow, G. J., Fauqueur, J., & Cipolla, R. (2008). Semantic object classes in video: A\n",
    "high-definition ground truth database. Pattern Recognition Letters.\n",
    "\n",
    "Brostow, G. J., Shotton, J., Fauqueur, J., & Cipolla, R. (2008). Segmentation and recognition\n",
    "using structure from motion point clouds. In Eccv (1) (p. 44-57)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
