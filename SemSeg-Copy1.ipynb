{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imread\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from utils import unpool_with_argmax\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file = 'CamVid/train.txt'\n",
    "val_file = 'CamVid/val.txt'\n",
    "test_file = 'CamVid/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT = 360\n",
    "IMAGE_WIDTH = 480\n",
    "IMAGE_DEPTH = 3\n",
    "NUM_CLASSES = 12\n",
    "TRAIN_BATCH_SIZE=8\n",
    "VAL_BATCH_SIZE=TRAIN_BATCH_SIZE\n",
    "TEST_BATCH_SIZE = 1\n",
    "NUM_ITERS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_label_colors():\n",
    "    Sky = [128,128,128]\n",
    "    Building = [128,0,0]\n",
    "    Pole = [192,192,128]\n",
    "    Road_marking = [255,69,0]\n",
    "    Road = [128,64,128]\n",
    "    Pavement = [60,40,222]\n",
    "    Tree = [128,128,0]\n",
    "    SignSymbol = [192,128,128]\n",
    "    Fence = [64,64,128]\n",
    "    Car = [64,0,128]\n",
    "    Pedestrian = [64,64,0]\n",
    "    Bicyclist = [0,128,192]\n",
    "    Unlabelled = [0,0,0]\n",
    "\n",
    "    label_colors = np.array([Sky, Building, Pole, Road, Pavement, Tree, SignSymbol, \n",
    "                             Fence, Car, Pedestrian, Bicyclist, Unlabelled])\n",
    "    return label_colors\n",
    "\n",
    "def img_annot_to_rgb(img_annot):\n",
    "    r = img_annot.copy()\n",
    "    g = img_annot.copy()\n",
    "    b = img_annot.copy()\n",
    "    label_colors = get_label_colors()\n",
    "    for i in range(len(label_colors)):\n",
    "        r[img_annot==i]=label_colors[i,0]\n",
    "        g[img_annot==i]=label_colors[i,1]\n",
    "        b[img_annot==i]=label_colors[i,2]\n",
    "    return np.stack([r,g,b],axis=2)/255.0\n",
    "\n",
    "def visualize_image_annot(img_data, annot_data, predicted_annot=None):\n",
    "    if predicted_annot is None:\n",
    "        fig, ax = plt.subplots(1,2,figsize=(10,12))\n",
    "        ax[0].imshow(img_data)\n",
    "        ax[0].set_title('Original Image')\n",
    "        ax[1].imshow(img_annot_to_rgb(annot_data))\n",
    "        ax[1].set_title('True Segmentation')\n",
    "        plt.show()\n",
    "    else:\n",
    "        fig, ax = plt.subplots(1,3,figsize=(10,12))\n",
    "        ax[0].imshow(img_data)\n",
    "        ax[0].set_title('Original Image')\n",
    "        ax[1].imshow(img_annot_to_rgb(predicted_annot))\n",
    "        ax[1].set_title('Predicted Segmentation')\n",
    "        ax[2].imshow(img_annot_to_rgb(annot_data))\n",
    "        ax[2].set_title('True Segmentation')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(file, train=True, batch_size=10, labels=True):\n",
    "    def _load_image(filename):\n",
    "        image_string = tf.read_file(filenames[0])\n",
    "        image_decoded = tf.image.decode_png(image_string, channels=3)\n",
    "        image_decoded = tf.image.convert_image_dtype(image_decoded,tf.float32)\n",
    "        return image_decoded\n",
    "\n",
    "    def _load_image_with_labels(filenames):\n",
    "        image_string = tf.read_file(filenames[0])\n",
    "        image_decoded = tf.image.decode_png(image_string, channels=3)\n",
    "        image_decoded = tf.image.convert_image_dtype(image_decoded,tf.float32)\n",
    "        annot_string = tf.read_file(filenames[1])\n",
    "        annot_decoded = tf.squeeze(tf.image.decode_image(annot_string),axis=2)\n",
    "        annot_decoded = tf.cast(annot_decoded, tf.int64)\n",
    "        return image_decoded, annot_decoded\n",
    "\n",
    "    dataset = tf.contrib.data.Dataset.from_tensor_slices(tf.constant([file]))\n",
    "    dataset =  dataset.flat_map(lambda filename: tf.contrib.data.TextLineDataset(filename))\n",
    "    dataset = dataset.map(lambda line: tf.string_split([line], delimiter=' ').values)\n",
    "    if labels:\n",
    "        dataset = dataset.map(_load_image_with_labels)\n",
    "    else:\n",
    "        dataset = dataset.map(_load_image)\n",
    "    if train is True:\n",
    "        dataset = dataset.shuffle(buffer_size=batch_size*3)\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    return iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference_scope(is_training, batch_norm_decay=0.9):\n",
    "    with slim.arg_scope([slim.conv2d],\n",
    "                        activation_fn=tf.nn.relu,\n",
    "                        weights_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "                        normalizer_fn=slim.batch_norm,\n",
    "                        stride=1,\n",
    "                        padding='SAME'):\n",
    "\n",
    "        with slim.arg_scope([slim.batch_norm],\n",
    "                            is_training=is_training,\n",
    "                            decay=batch_norm_decay) as scope:\n",
    "            return scope\n",
    "\n",
    "def inference(images, class_inc_bg = None):\n",
    "\n",
    "    tf.summary.image('input', images, max_outputs=3)\n",
    "\n",
    "    with tf.variable_scope('pool1'):\n",
    "        net = slim.conv2d(images, 64, [3, 3], scope='conv1_1')\n",
    "        net = slim.conv2d(net, 64, [3, 3], scope='conv1_2')\n",
    "        net, arg1 = tf.nn.max_pool_with_argmax(net, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='maxpool1')\n",
    "\n",
    "    with tf.variable_scope('pool2'):\n",
    "        net = slim.conv2d(net, 128, [3, 3], scope='conv2_1')\n",
    "        net = slim.conv2d(net, 128, [3, 3], scope='conv2_2')\n",
    "        net, arg2 = tf.nn.max_pool_with_argmax(net, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='maxpool2')\n",
    "\n",
    "    with tf.variable_scope('pool3'):\n",
    "        net = slim.conv2d(net, 256, [3, 3], scope='conv3_1')\n",
    "        net = slim.conv2d(net, 256, [3, 3], scope='conv3_2')\n",
    "        net = slim.conv2d(net, 256, [3, 3], scope='conv3_3')\n",
    "        net, arg3 = tf.nn.max_pool_with_argmax(net, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='maxpool3')\n",
    "\n",
    "    with tf.variable_scope('unpool3'):\n",
    "        net = unpool_with_argmax(net, arg3, name='maxunpool3')\n",
    "        net = slim.conv2d(net, 256, [3, 3], scope='uconv3_3')\n",
    "        net = slim.conv2d(net, 256, [3, 3], scope='uconv3_2')\n",
    "        net = slim.conv2d(net, 128, [3, 3], scope='uconv3_1')\n",
    "\n",
    "    with tf.variable_scope('unpool2'):\n",
    "        net = unpool_with_argmax(net, arg2, name='maxunpool2')\n",
    "        net = slim.conv2d(net, 128, [3, 3], scope='uconv2_2')\n",
    "        net = slim.conv2d(net, 64, [3, 3], scope='uconv2_1')\n",
    "\n",
    "    with tf.variable_scope('unpool1'):\n",
    "        net = unpool_with_argmax(net, arg1, name='maxunpool1')\n",
    "        net = slim.conv2d(net, 64, [3, 3], scope='uconv1_2')\n",
    "        logits = slim.conv2d(net, class_inc_bg, [3, 3], scope='uconv1_1')\n",
    "    predicted_annotations = tf.argmax(logits,axis=3)\n",
    "    return logits, predicted_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "train_iterator = load_data(train_file, batch_size=TRAIN_BATCH_SIZE)\n",
    "val_iterator = load_data(val_file, train=False, batch_size=TRAIN_BATCH_SIZE)\n",
    "test_iterator = load_data(test_file, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_inputs(batch_size):\n",
    "    inputs = tf.placeholder(tf.float32, [batch_size, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH ])\n",
    "    labels = tf.placeholder(tf.int64,[batch_size, IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "    return inputs, labels, is_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss(logits, labels):\n",
    "    ce = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n",
    "    loss = tf.reduce_mean(ce)\n",
    "    tf.summary.scalar('loss', loss)\n",
    "    return loss\n",
    "\n",
    "def compute_accuracy(logits, labels):\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 3), labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    return accuracy\n",
    "\n",
    "def training_op(loss, learning_rate):\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.1).minimize(loss, global_step=global_step)\n",
    "    return optimizer, global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_scope = inference_scope(is_training=True, batch_norm_decay=0.95)\n",
    "inputs, labels, is_training = get_inputs(batch_size=TRAIN_BATCH_SIZE)\n",
    "with slim.arg_scope(arg_scope):\n",
    "    logits, predicted_annotations = inference(inputs, class_inc_bg=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = compute_loss(logits, labels)\n",
    "optimizer, global_step = training_op(loss, 0.0001)\n",
    "accuracy = compute_accuracy(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(train_iterator.initializer)\n",
    "\n",
    "for i in range(NUM_ITERS):\n",
    "    train_image, train_labels =sess.run(train_iterator.get_next())\n",
    "    if len(train_image) < TRAIN_BATCH_SIZE:\n",
    "        sess.run(train_iterator.initializer)\n",
    "        train_image, train_labels =sess.run(train_iterator.get_next())\n",
    "    _, loss_,accuracy_ = sess.run([optimizer,loss, accuracy], feed_dict={inputs: train_image, labels:train_labels,\n",
    "                                                  is_training: True})\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(loss_, accuracy_)\n",
    "        if i > 0:\n",
    "            sess.run(val_iterator.initializer)\n",
    "            val_image, val_labels = sess.run(val_iterator.get_next())\n",
    "            preds = sess.run(predicted_annotations, feed_dict={inputs: val_image, labels:val_labels,\n",
    "                                                         is_training: False})\n",
    "            visualize_image_annot(val_image[0],val_labels[0],preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reshape(k,[-1,11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visualize_image_annot(val_image[1],val_labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visualize_image_annot(val_image[1],preds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv(inputs,[3,3],[3,64],1,'c1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.get_shape().as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.ops import gen_nn_ops\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "\n",
    "def unpool_with_argmax(pool, ind, name = None, ksize=[1, 2, 2, 1]):\n",
    "\n",
    "    \"\"\"\n",
    "       Unpooling layer after max_pool_with_argmax.\n",
    "       Args:\n",
    "           pool:   max pooled output tensor\n",
    "           ind:      argmax indices\n",
    "           ksize:     ksize is the same as for the pool\n",
    "       Return:\n",
    "           unpool:    unpooling tensor\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(name):\n",
    "        input_shape = pool.get_shape().as_list()\n",
    "        output_shape = (input_shape[0], input_shape[1] * ksize[1], input_shape[2] * ksize[2], input_shape[3])\n",
    "\n",
    "        flat_input_size = np.prod(input_shape)\n",
    "        flat_output_shape = [output_shape[0], output_shape[1] * output_shape[2] * output_shape[3]]\n",
    "\n",
    "        pool_ = tf.reshape(pool, [flat_input_size])\n",
    "        batch_range = tf.reshape(tf.range(output_shape[0], dtype=ind.dtype), shape=[input_shape[0], 1, 1, 1])\n",
    "        b = tf.ones_like(ind) * batch_range\n",
    "        b = tf.reshape(b, [flat_input_size, 1])\n",
    "        ind_ = tf.reshape(ind, [flat_input_size, 1])\n",
    "        ind_ = tf.concat([b, ind_], 1)\n",
    "\n",
    "        ret = tf.scatter_nd(ind_, pool_, shape=flat_output_shape)\n",
    "        ret = tf.reshape(ret, output_shape)\n",
    "        return ret\n",
    "\n",
    "\n",
    "@ops.RegisterGradient(\"MaxPoolWithArgmax\")\n",
    "def _MaxPoolGradWithArgmax(op, grad, unused_argmax_grad):\n",
    "    return gen_nn_ops._max_pool_grad_with_argmax(op.inputs[0],\n",
    "                                                 grad,\n",
    "                                                 op.outputs[1],\n",
    "                                                 op.get_attr(\"ksize\"),\n",
    "                                                 op.get_attr(\"strides\"),\n",
    "                                                 padding=op.get_attr(\"padding\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
